<!DOCTYPE html><html lang="zh-CN" data-theme="dark"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no"><title>LangChain教程(一):提示词工程与任务编排 | 宋书生</title><meta name="keywords" content="AIGC、Python、LangChain"><meta name="author" content="宋书生"><meta name="copyright" content="宋书生"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#18171d"><meta name="mobile-web-app-capable" content="yes"><meta name="apple-touch-fullscreen" content="yes"><meta name="apple-mobile-web-app-title" content="LangChain教程(一):提示词工程与任务编排"><meta name="application-name" content="LangChain教程(一):提示词工程与任务编排"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="#18171d"><meta property="og:type" content="article"><meta property="og:title" content="LangChain教程(一):提示词工程与任务编排"><meta property="og:url" content="https://blog.smallscholar.com/AIGC/langchainBasic/index.html"><meta property="og:site_name" content="宋书生"><meta property="og:description" content="前言：本文涉及到的所有代码均可从LangChain教程中获取  一、LangChain组件介绍与快速入门1. Langchain简介LangChain 是一个开源的 Python AI 应用开发框架, 它提供了构建基于大模型的 AI 应用所需的模块和工具。通过 LangChain, 开发者可以轻松"><meta property="og:locale" content="zh-CN"><meta property="og:image" content="https://bu.dusays.com/2025/05/22/682e07ffea50a.png"><meta property="article:author" content="宋书生"><meta property="article:tag"><meta name="twitter:card" content="summary"><meta name="twitter:image" content="https://bu.dusays.com/2025/05/22/682e07ffea50a.png"><meta name="description" content="前言：本文涉及到的所有代码均可从LangChain教程中获取  一、LangChain组件介绍与快速入门1. Langchain简介LangChain 是一个开源的 Python AI 应用开发框架, 它提供了构建基于大模型的 AI 应用所需的模块和工具。通过 LangChain, 开发者可以轻松"><link rel="shortcut icon" href="/favicon.ico"><link rel="canonical" href="https://blog.smallscholar.com/AIGC/langchainBasic/"><link rel="preconnect" href="//cdn.cbd.int"><link rel="preconnect" href="//www.google-analytics.com" crossorigin=""><link rel="preconnect" href="//hm.baidu.com"><link rel="preconnect" href="//busuanzi.ibruce.info"><meta name="google-site-verification" content="xxx"><meta name="baidu-site-verification" content="codeva-vxWGXRA3Ih"><meta name="msvalidate.01" content="xxx"><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-tag-plugins-plus@1.0.17/lib/assets/font-awesome-animation.min.css"><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.cbd.int/@fortawesome/fontawesome-free@6.4.0/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.cbd.int/node-snackbar@0.1.16/dist/snackbar.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.cbd.int/@fancyapps/ui@5.0.28/dist/fancybox/fancybox.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://npm.elemecdn.com/anzhiyu-theme-static@1.0.0/swiper/swiper.min.css" media="print" onload="this.media='all'"><script>var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?599c9479eb34ef2a396e4cebb2ffa9e0";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script><script async="async" src="https://www.googletagmanager.com/gtag/js?id=G-8TT6FESDJF"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-8TT6FESDJF');
</script><script>const GLOBAL_CONFIG = {
  linkPageTop: {"enable":true,"title":"与数百名博主无限进步","addFriendPlaceholder":"昵称（请勿包含博客等字样）：\n网站地址（要求博客地址，请勿提交个人主页）：\n头像图片url（请提供尽可能清晰的图片，我会上传到我自己的图床）：\n描述：\n站点截图（可选）：\n"},
  peoplecanvas: undefined,
  postHeadAiDescription: {"enable":true,"gptName":"AnZhiYu","mode":"tianli","switchBtn":false,"btnLink":"https://afdian.net/item/886a79d4db6711eda42a52540025c377","randomNum":3,"basicWordCount":1000,"key":"P-GS0M11ST8FWSKKMC","Referer":"https://blog.smallscholar.com/"},
  diytitle: undefined,
  LA51: {"enable":true,"ck":"3K9KMNEUXUi8jPrf","LingQueMonitorID":"3K9KMNEUXUi8jPrf"},
  greetingBox: {"enable":true,"default":"晚上好👋","list":[{"greeting":"晚安😴","startTime":0,"endTime":5},{"greeting":"早上好鸭👋, 祝你一天好心情！","startTime":6,"endTime":9},{"greeting":"上午好👋, 状态很好，鼓励一下～","startTime":10,"endTime":10},{"greeting":"11点多啦, 在坚持一下就吃饭啦～","startTime":11,"endTime":11},{"greeting":"午安👋, 宝贝","startTime":12,"endTime":14},{"greeting":"🌈充实的一天辛苦啦！","startTime":14,"endTime":18},{"greeting":"19点喽, 奖励一顿丰盛的大餐吧🍔。","startTime":19,"endTime":19},{"greeting":"晚上好👋, 在属于自己的时间好好放松😌~","startTime":20,"endTime":24}]},
  twikooEnvId: 'https://smallscholar-twikoo.hf.space',
  commentBarrageConfig:{"enable":true,"maxBarrage":1,"barrageTime":4000,"accessToken":"","mailMd5":""},
  music_page_default: "nav_music",
  root: '/',
  preloader: {"source":3},
  friends_vue_info: {"apiurl":"https://friends.anheyu.com/"},
  navMusic: true,
  mainTone: {"mode":"api","api":"https://img2color-go.vercel.app/api?img=","cover_change":true},
  authorStatus: undefined,
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":true,"languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: {"defaultEncoding":2,"translateDelay":0,"msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"简","rightMenuMsgToTraditionalChinese":"转为繁体","rightMenuMsgToSimplifiedChinese":"转为简体"},
  noticeOutdate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":330},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    simplehomepage: true,
    post: false
  },
  runtime: '天',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: {"copy":true,"copyrightEbable":true,"limitCount":50,"languages":{"author":"作者: 宋书生","link":"链接: ","source":"来源: 宋书生","info":"著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。","copySuccess":"复制成功，复制和转载请标注本文地址"}},
  lightbox: 'fancybox',
  Snackbar: {"chs_to_cht":"你已切换为繁体","cht_to_chs":"你已切换为简体","day_to_night":"你已切换为深色模式","night_to_day":"你已切换为浅色模式","bgLight":"#425AEF","bgDark":"#1f1f1f","position":"top-center"},
  source: {
    justifiedGallery: {
      js: 'https://cdn.cbd.int/flickr-justified-gallery@2.1.2/dist/fjGallery.min.js',
      css: 'https://cdn.cbd.int/flickr-justified-gallery@2.1.2/dist/fjGallery.css'
    }
  },
  isPhotoFigcaption: true,
  islazyload: true,
  isAnchor: false,
  shortcutKey: undefined,
  autoDarkmode: true
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  configTitle: '宋书生',
  title: 'LangChain教程(一):提示词工程与任务编排',
  postAI: 'true',
  pageFillDescription: '一、LangChain组件介绍与快速入门, 1. Langchain简介, 2. LangChain 特性, 3. LangChain 框架组成, 4. LangChain 库 (Libraries), 5. langchain 任务处理流程, 6. LangChain核心概念, 7. LangChain应用场景, 8. LangChain快速入门, 安装LangChain, 初始化模型, 使用LLM, 输出转换, 二、LangChain提示词工程应用实践, 1. 什么是提示词模板？, 2. 如何创建提示词模板(prompt template), 创建一个普通提示词模板, 创建聊天消息提示词模板, 在创建模板时使用MessagesPlaceholder, 提示词追加示例, 3. 使用示例集, 创建示例集, 创建小样本示例的格式化程序, 将示例和格式化程序提供给FewShotPromptTemplate, 4. 使用示例选择器, 将示例提供给ExampleSelector, 将示例选择器提供给FewShotPromptTemplate, 三、LangChain工作流编排, 1. LCEL介绍, 2. Runable interface介绍, 3. Stream(流), LLM 和聊天模型, Chain(链), 4. Stream events(事件流), 事件参考, 聊天模型, 四、结语前言本文涉及到的所有代码均可从教程中获取一组件介绍与快速入门简介是一个开源的应用开发框架它提供了构建基于大模型的应用所需的模块和工具通过开发者可以轻松地与大型语言模型集成完成文本生成问答翻译对话等任务降低了应用开发的门槛让任何人都可以基于构建属于自己的创意应用特性和提示抽象与统一接口通过组件如为不同大模型如阿里通义等提供统一接口开发者无需关心底层差异只需通过配置即可切换模型例如使用阿里通义模型时只需设置并调用类模板管理的支持动态变量插入与多模板组合例如通过可将系统角色示例对话和用户输入拼接为完整提示提升代码复用性此外会根据输入长度或语义相似度动态选择示例优化使用链预置链与自定义链内置了常见的任务链如问答链摘要链也支持通过自定义逻辑例如可以将自然语言转换为语句再通过执行查询最终用自然语言解释结果这种链式设计将复杂流程分解为可组合的步骤适合构建端到端应用链的灵活性开发者可通过串联多个链每个步骤可使用不同模型或工具例如先调用解析用户意图再调用搜索获取数据最后生成响应工作流编排通过声明式语法定义任务流程例如使用传递上下文结合运算符连接组件如提示模板模型调用输出解析器实现流水线处理还支持异步流式处理和错误重试等功能数据增强生成解决限制与数据实时性通过加载外部数据如网页使用分割长文本再通过模型向量化后存入向量数据库如查询时检索相关段落注入提示词增强模型回答的准确性与时效性作为决策引擎将作为大脑根据用户目标自主调用工具如计算器数据库完成不同的工作例如可解析自然语言指令生成代码操作而能将统计月渠道访客数的指令转换为查询并执行动态决策流程通过框架循环执行思考行动观察步骤直至完成任务例如用户提问明天天气如何时可能先调用天气再结合结果生成回复模型记忆上下文管理提供多种记忆组件存储完整对话历史压缩历史为摘要提取关键实体这些组件可集成到链或中支持多轮对话场景框架组成框架由几个部分组成包括库和库包含接口和集成多种组件的运行时基础以及现成的链和代理的实现模板官方提供的一些任务模板通过部署链支持快速集成到现有系统例如将查询链发布为供前端调用提供全生命周期管理包括调试时追踪链的执行步骤生产环境监控性能与异常还可以通过评估工具优化提示词库库本身由几个不同的包组成基础抽象和表达语言第三方集成主要包括集成的第三方组件主要包括链代理和检索策略任务处理流程如上图提供一套提示词模板管理工具负责处理提示词然后传递给大模型处理最后处理大模型返回的结果对大模型的封装主要包括和两种类型问答模型模型接收一个文本输入然后返回一个文本结果对话模型接收一组对话消息然后返回对话消息类似聊天消息一样核心概念封装的基础模型模型接收一个文本输入然后返回一个文本结果聊天模型或者成为对话模型与不同这些模型专为对话场景而设计模型可以接收一组对话消息然后返回对话消息类似聊天消息一样消息指的是聊天模型的消息内容消息类型包括包括和等多种类型的消息提示封装了一组专门用于提示词管理的工具类方便我们格式化提示词内容输出解析器如上图介绍接受大模型返回的文本内容之后可以使用专门的输出解析器对文本内容进行格式化例如解析或者将输出的内容转成对象为方便我们将私有数据导入到大模型提高模型回答问题的质量封装了检索框架方便我们加载文档数据切割文档数据存储和检索文档数据向量存储为支持私有数据的语义相似搜索支持多种向量数据库智能体通常指的是以大模型作为决策引擎根据用户输入的任务自动调用外部系统硬件设备共同完成用户的任务是一种以大模型为核心的应用设计模式应用场景对话机器人构建智能的对话助手客服机器人聊天机器人等知识库问答结合知识图谱进行开放域问题的问答服务智能写作如文章写作创意写作文本摘要等快速入门安装我们可以使用和安装相关依赖以下是相关库以及后续学习时所需要的依赖初始化模型在使用之前需要导入集成包并设置的密钥作为环境变量或直接传递给类首先我们需要先获取密钥可以通过创建账户并访问此链接来获取然后可以将密钥设置为环境变量方法如下首先在项目的根目录中创建文件然后添加如下信息接下来初始化模型加载文件中的环境变量使用使用来回答问题非常简单可以直接调用的方法并传入问题作为参数此外还可以通过提示模板生成提示词用于向模型发送指令下面演示了如何构建一个简单的链创建一个提示模板这里以对话模型的消息格式为例子不熟悉对话模型消息格式建议先学习的教程下面消息模板定义两条消息消息告诉模型扮演什么角色消息代表用户输入的问题这里用了一个占位符代表接受一个模版参数你是一个著名的宋词研究学者基于表达式构建链语法类似的语法从左到右按顺序执行下面编排了一个简单的工作流首先执行完成提示词模板格式化处理然后将格式化后的传递给模型执行最终返回执行结果调用链并设置模板参数会把调用参数传递给提示模板开始定义的步骤开始逐步执行以怀才不遇壮志难酬为主题写一首词牌名为水调歌头的词模型响应如下可见相较于国产的其他模型来说还是非常强大的水调歌头书愤长剑倚天啸孤影立寒秋十年磨尽霜刃空负少年头欲挽银河洗甲却叹冯唐易老壮志几时酬醉眼望星斗清泪落吴钩匣中鸣弦上恨总难休男儿意气何日能破玉门囚纵使封侯无分也要昆仑勒石浩气贯神州莫道书生拙风雨会中流输出转换的输出通常是一条消息为了更方便处理结果可以将消息转换为字符串下面展示如何将的输出消息转换为字符串引入聊天场景的提示词模版根据生成提示词模版你是一个著名的宋词研究学者创建一个字符串输出解析器通过的链式调用生成一个以怀才不遇壮志难酬为主题写一首词牌名为水调歌头的词水调歌头书愤长剑倚天啸孤影对残灯十年磨就霜刃无处试锋棱欲驾长鲸碧海却困蓬蒿荻苇风雨暗相惊醉眼挑灯看匣底作龙鸣射斗牛光焰动为谁明男儿意气空负燕颔虎头形纵使封侯有骨无奈时乖命蹇白发已丛生且尽杯中物卧听晚潮声注本词通过长剑霜刃等意象表现志士的英武气概以困蓬蒿白发丛生等语道出英雄失路的悲愤下阕连用射斗牛燕颔虎头典故强化怀才不遇主题结句卧听晚潮以景结情留下苍凉余韵全词跌宕起伏符合词牌声情特点通过上面短短十几行的代码我们就可以利用框架让大模型给我们打工了可见解决使用大模型还是非常简单的二提示词工程应用实践什么是提示词模板上面也有介绍语言模型以文本作为输入这个文本通常被称为提示词在开发过程中对于提示词通常不能直接硬编码不利于提示词管理而是通过提示词模板进行维护类似开发过程中遇到的短信模板邮件模板等等提示词模板本质上跟平时大家使用的邮件模板短信模板没什么区别就是一个字符串模板模板可以包含一组模板参数通过改变参数值可以替换模板对应的参数一个提示词模板可以包含以下内容发给大语言模型的指令一组问答示例以提醒以什么格式返回请求发给语言模型的问题如何创建提示词模板创建一个普通提示词模板我们可以使用类创建简单的提示词提示词模板可以内嵌任意数量的模板参数然后通过参数值格式化模板内容定义一个提示模板包含和两个模板变量模板变量使用包括起来给我讲一个关于的笑话通过模板参数格式化提示模板书生求学冷模板输出结果给我讲一个关于书生求学的冷笑话创建聊天消息提示词模板聊天模型以聊天消息列表作为输入这个聊天消息列表的消息内容也可以通过提示词模板进行管理这些聊天消息与原始字符串不同因为每个消息都与角色相关联例如在的中的聊天模型给不同的聊天消息定义了三种角色类型分别是助手人类或系统角色助手消息指的是当前消息是回答的内容人类消息指的是你发给的内容系统消息通常是用来给身份进行描述创建聊天消息模板例子导入提示词模版库通过一个消息数组创建聊天消息模板数组每一个元素代表一条消息每个消息元组第一个元素代表消息角色也成为消息类型第二个元素代表消息内容消息角色代表系统消息代表人类消息代表返回的消息内容下面消息定义了个模板参数和你是一名人工智能助手你的名字是你好我很好谢谢通过模板参数格式化模板内容你的名字叫什么你是一名人工智能助手你的名字是你好我很好谢谢你的名字叫什么另外一种消息格式例子使用定义的等工具类定义消息跟前面的例子类似下面定义了两条消息你是一个乐于助人的助手使用模板参数格式化模板书生喜欢古诗词你是一个乐于助人的助手可以润色内容使其看起来起来更简单易读我不喜欢吃好吃的东西通常我们不会直接使用函数格式化提示模板内容而是交给框架自动处理在创建模板时使用这个提示模板负责在特定位置添加消息列表在上面的中我们看到了如何格式化两条消息每条消息都是一个字符串但是如果我们希望用户传入一个消息列表我们将其插入到特定位置该怎么办这就是的作用你是宋书生的人工智能助手可以传入一组消息你好你好我是宋书生你是宋书生的人工智能助手你好你好我是宋书生以上代码将生成两条消息第一条是系统消息第二条是我们传入的如果我们传入了条消息那么总共会生成条消息系统消息加上传入的条消息这对于将一系列消息插入到特定位置非常有用另一种实现相同效果的替代方法是不直接使用类而是你是宋书生的人工智能助手这是更改的部分提示词追加示例提示词中包含交互样本的作用是为了帮助模型更好地理解用户的意图从而更好地回答问题或执行任务小样本提示模板是指使用一组少量的示例来指导模型处理新的输入这些示例可以用来训练模型以便模型可以更好地理解和回答类似的问题例子什么是宋书生宋书生是一个励志成为精通的愣头青什么是宋铁柱未知什么是语言模型告诉模型根据是问题是答案按这种格式进行问答交互下面讲解的就是针对在提示词中插入少量交互样本提供的工具类使用示例集创建示例集下面定义一个示例数组里面包含一组问答样例珠穆朗玛峰和富士山哪一座山的首次登顶时间更早这里需要跟进问题吗是的跟进珠穆朗玛峰的首次登顶时间是什么时候中间答案珠穆朗玛峰于年月日首次被登顶跟进富士山的首次登顶时间是什么时候中间答案富士山在公元年已有朝圣者登顶记录所以最终答案是富士山特斯拉和的是否曾就读于同一所大学这里需要跟进问题吗是的跟进特斯拉的是谁中间答案特斯拉的是跟进曾就读于哪所大学中间答案他曾在宾夕法尼亚大学学习跟进的是谁中间答案的也是所以最终答案是是哈利波特系列和魔戒系列的作者是否都出生于英国这里需要跟进问题吗是的跟进哈利波特的作者是谁中间答案跟进的出生地是哪里中间答案她出生于英国格洛斯特郡跟进魔戒的作者是谁中间答案跟进的出生地是哪里中间答案他出生于南非奥兰治自由邦所以最终答案是不是创建小样本示例的格式化程序通过对象我们可以非常简单的在提示词模板中插入样例问题提取示例集合的一个示例的内容用于格式化模板内容返回问题珠穆朗玛峰和富士山哪一座山的首次登顶时间更早这里需要跟进问题吗是的跟进珠穆朗玛峰的首次登顶时间是什么时候中间答案珠穆朗玛峰于年月日首次被登顶跟进富士山的首次登顶时间是什么时候中间答案富士山在公元年已有朝圣者登顶记录所以最终答案是富士山将示例和格式化程序提供给通过对象批量插入示例内容接收示例数组参数通过提示词模板批量渲染示例内容和参数用于在提示词模板最后追加内容用于定义中包含的模板参数问题魔戒的作者是谁返回问题珠穆朗玛峰和富士山哪一座山的首次登顶时间更早这里需要跟进问题吗是的跟进珠穆朗玛峰的首次登顶时间是什么时候中间答案珠穆朗玛峰于年月日首次被登顶跟进富士山的首次登顶时间是什么时候中间答案富士山在公元年已有朝圣者登顶记录所以最终答案是富士山问题特斯拉和的是否曾就读于同一所大学这里需要跟进问题吗是的跟进特斯拉的是谁中间答案特斯拉的是跟进曾就读于哪所大学中间答案他曾在宾夕法尼亚大学学习跟进的是谁中间答案的也是所以最终答案是是问题哈利波特系列和魔戒系列的作者是否都出生于英国这里需要跟进问题吗是的跟进哈利波特的作者是谁中间答案跟进的出生地是哪里中间答案她出生于英国格洛斯特郡跟进魔戒的作者是谁中间答案跟进的出生地是哪里中间答案他出生于南非奥兰治自由邦所以最终答案是不是问题魔戒的作者是谁使用示例选择器将示例提供给这里重用前一部分中的示例集和提示词模板但是不会将示例直接提供给对象把全部示例插入到提示词中而是将它们提供给一个对象插入部分示例这里我们使用类该类根据与输入的相似性选择小样本示例它使用嵌入模型计算输入和小样本示例之间的相似性然后使用向量数据库执行相似搜索获取跟输入相似的示例提示这里涉及向量计算向量数据库在领域这两个主要用于数据相似度搜索例如查询相似文章内容相似的图片视频等等这里使用了的向量数据库以及阿里的模型目前先做了解会在后面教程中详细介绍使用阿里的使用语义相似性示例选择器这是可供选择的示例列表这是用于生成嵌入的嵌入类该嵌入用于衡量语义相似性这是用于存储嵌入和执行相似性搜索的类这是要生成的示例数选择与输入最相似的示例哈利波特的作者是哪个国家的最相似的示例这里匹配了跟问题相似的例子下面是返回最相似的示例哈利波特的作者是哪个国家的这里需要跟进问题吗是的跟进哈利波特的作者是谁中间答案跟进的出生地是哪里中间答案她出生于英国格洛斯特郡跟进魔戒的作者是谁中间答案跟进的出生地是哪里中间答案他出生于南非奥兰治自由邦所以最终答案是不是哈利波特系列和魔戒系列的作者是否都出生于英国将示例选择器提供给最后创建一个对象根据前面的示例选择器选择一个跟问题相似的例子选择与输入最相似的示例珠穆朗玛峰的首次登山时间问题问题珠穆朗玛峰的首次登山时间返回问题珠穆朗玛峰和富士山哪一座山的首次登顶时间更早这里需要跟进问题吗是的跟进珠穆朗玛峰的首次登顶时间是什么时候中间答案珠穆朗玛峰于年月日首次被登顶跟进富士山的首次登顶时间是什么时候中间答案富士山在公元年已有朝圣者登顶记录所以最终答案是富士山问题珠穆朗玛峰的首次登山时间通过上面的讲解大家可以发现中的提示词模板使用起来简单又方便我们仅需要少量的代码就可以显著的增强大模型在特定领域的能力还是非常推荐大家在以后使用大模型或者进行开发时多多使用提示词工程毕竟性价比贼高三工作流编排介绍是一种强大的工作流编排工具可以通过基本组件构建复杂任务链条并支持诸如流式处理并行处理和日志记录等开箱即用的功能从一开始就被设计为支持将原型投入生产无需更改代码从最简单的提示链到最复杂的链甚至有人成功地在生产中运行了包含数百步的链以下是你可能想要使用的一些原因一流的流式支持通过构建的链式流程能够实现首个标记极速响应即从请求发出到获取第一个输出块的最小延迟对于支持流式处理的链系统可直接将大模型生成的原始标记实时传输至流式解析器最终输出速率与模型原生输出速率完全同步这种机制尤其适合需要实时交互的场景如对话式异步支持所有基于构建的链均支持同步与异步双模式调用同步模式适用于等交互式开发环境便于快速原型验证异步模式可无缝集成至服务端实现高并发请求处理开发者可使用同一套代码完成从实验到生产的全流程兼顾开发效率与线上性能优化的并行执行自动识别链中可并行化的环节例如同时从多个检索器获取文档并在同步异步接口中自动启用并行执行最大限度降低整体延迟此特性在复杂工作流中可提升的吞吐效率重试和回退重试与回退策略可为链的任意环节配置自动重试规则和备用降级方案显著增强系统在规模化场景下的鲁棒性流式兼容性开发中未来版本将支持重试操作与流式输出的无缝结合实现可靠性提升与零延迟代价的兼得访问中间结果在复杂链执行过程中开发者可实时获取中间步骤的结果流此功能既可用于终端用户的状态提示如显示正在检索文档也能辅助开发阶段的调试追踪该特性已全面支持服务端输入和输出模式为每个链自动生成基于和的数据契约输入校验拒绝不符合模式的非法请求输出标准化确保响应结构符合预期降低下游系统集成成本此特性是服务的核心基础也是构建企业级应用的关键保障介绍通过协议标准化组件交互接口大幅降低自定义链开发复杂度该协议覆盖以下核心组件基础模型聊天模型大语言模型数据处理模块输出解析器检索器模板工具提示模板扩展组件支持开发者自定义实现的任意可运行对象标准接口方法方法功能描述适用场景同步调用链输入单个参数并返回完整结果简单请求的同步处理流式传输响应数据块逐块生成输出结果实时交互长文本生成批量处理输入列表返回对应结果集合高吞吐批量任务异步接口扩展为支持高并发场景所有方法均提供异步版本需配合使用异步方法核心特性版本要求异步单请求处理非阻塞执行基础支持异步流式输出支持实时数据传输基础支持异步批量处理优化资源利用率基础支持流式返回中间过程日志及最终结果实现执行过程可视化基础支持级事件流接口实时推送链执行事件如工具调用模型响应其中输入类型和输出类型因组件而异组件输入类型输出类型提示字典提示值聊天模型单个字符串聊天消息列表或提示值聊天消息单个字符串聊天消息列表或提示值字符串输出解析器或聊天模型的输出取决于解析器检索器单个字符串文档列表工具单个字符串或字典取决于工具取决于工具所有实现接口的对象均通过以下机制确保数据规范性基于组件结构自动生成的输入模型通过运行时类型推导生成的输出模型流式处理能力是构建响应式应用的关键通过统一接口实现全链路流式支持如聊天模型输出解析器提示模板检索器和代理都实现了接口该接口提供了两种通用的流式内容方法同步和异步流式传输链中最终输出的默认实现异步和异步前者为事件驱动流主要用途为实时监控审计日志后者为过程监控流主要用途为开发调试用户进度提示接下来我们将学习这两种流式方法流所有对象都实现了名为的同步方法和名为的异步方法这两个方法旨在以数据块的形式流式传输最终输出尽可能快地返回每个处理单元流式传输的实现前提是程序中的所有处理步骤都支持流式输入处理即能够逐个处理输入数据块并生成对应的输出块处理复杂度根据场景不同存在差异从简单的任务如输出生成的令牌到复杂场景如在完整生成结果前流式传输部分内容均有覆盖让我们从应用程序的核心组件开始探索本身和聊天模型大型语言模型及其聊天模型变体是构建应用程序的主要性能瓶颈大型语言模型生成完整响应通常需要数秒时间远超保持应用响应性所需的毫秒阈值提升应用响应性的核心策略在于实时展示中间处理进度即通过逐个令牌流式传输模型的输出以下为聊天模型的流式传输示例演示让我们从同步开始宋词的前身是什么如果你在异步环境中工作可以考虑使用异步异步流处理宋词的前身是什么判断长度为的时候打印运行异步流处理让我们检查其中一个块宋可以得到了一个称为的东西该块表示的一部分消息块是可叠加的可以简单地将它们相加以获得到目前为止的响应状态宋词的前身链绝大多数应用程序都包含多步骤操作流程而非仅执行单一的语言模型调用我们通过表达式语言构建一个基础处理链该链整合提示模板模型组件及解析器模块并验证流式传输机制的有效性采用进行模型输出解析该解析器通过从中提取字段内容实现模型生成的标准化输出采用声明式编程范式通过组合基础组件构建完整工作流程基于创建的链自动支持与方法天然具备最终输出的流式传输能力值得注意的是所有构建的链均完整实现了标准接口规范给我讲一个关于的笑话工作运行异步流处理输出好的这是一个关于工作的经典笑话老板我们公司崇尚平等在这里没有等级观念新员工太好了那我可以直接叫你名字吗老板当然可以新员工好的老王老板叫我王总冷笑话平等的前提是总得有人加班希望让你会心一笑需特别指出即使我们在上述处理链末端添加了解析器组件仍能保持流式输出能力解析器会对每个流式数据块进行即时处理许多基础组件均原生支持这种增量式流式传递特性极大提升了应用构建效率开发者可设计返回生成器的自定义函数以此实现流式数据操作能力需注意部分可运行对象如提示模板和聊天模型因需聚合前序步骤的完整结果无法处理独立数据块此类组件将中断流式处理流程表达式语言实现了链式架构与调用模式的解耦如同步异步批处理流式等对于无需复杂编排的场景开发者仍可采用命令式编程范式通过或方法调用各组件将执行结果存入变量后传递至下游处理使用输入流若需要实现的增量流式解析传统方案将面临技术挑战直接使用解析不完整的片段会因格式无效导致解析失败表面上看这似乎宣告了流式解析的不可行性实际上通过构建支持输入流处理的解析器可实现智能补全机制该解析器持续接收输入流片段动态推测并补全结构至有效状态以下通过实际运行演示解析器的核心工作机制由于旧版本中的一个错误未能从某些模型中流式传输结果以格式输出中国美国和印度的国家及其人口列表使用一个带有外部键的字典其中包含国家列表每个国家都应该有键和运行异步流处理输出中国中国中国中国中国中国中国中国美国中国美国中国美国中国美国中国美国中国美国中国美国印度中国美国印度中国美国印度中国美国印度中国美国印度事件流现在我们已经了解了和的工作原理让我们进入事件流的世界事件流是一个这个可能会根据用户反馈略微更改本指南演示了并且需要对于与旧版本兼容的请参阅这里查看版本为确保的正常运行需严格遵循以下实现原则异步优先在代码架构中优先采用异步编程模式回调传播定义自定义函数可运行对象时需确保回调函数的完整传递流式强制未使用时对组件调用而非以激活流式令牌生成事件参考下表列举不同可运行对象可能触发的事件类型当流式处理正确实现时可运行对象的输入信息通常只能在输入流完全处理完成后确定这意味着字段通常仅出现在结束阶段事件中而不会包含在开始阶段事件中事件名称块输入输出模型名称模型名称模型名称模型名称模型名称检索器名称检索器名称模板名称模板名称聊天模型首先让我们看一下聊天模型产生的事件异步流处理运行异步流处理输出关于接口中参数的技术注解此为版其规范可能发生变更实际已进行过多次调整版本参数的设置旨在最大限度降低代码兼容性风险当前的设计旨在减少未来版本升级对现有代码的破坏性影响注意版本仅支持建议通过更新依赖四结语作为开源框架通过模块化设计灵活的链式调用和强大的工具集成能力为开发者提供了构建大语言模型应用的高效路径其核心价值体现在技术整合统一多种模型如等的接口支持等复杂场景解决了实时性与数据局限性的矛盾工程化能力通过的监控调试的部署实现从开发到生产的全生命周期管理生态扩展活跃的社区与丰富的第三方集成如向量数据库文档加载器降低了开发门槛推动应用的快速迭代本文介绍了的相关组件特性框架组成核心概念等内容此外还着重介绍了提示词工程应用实践工作流编排等内容展示了如何使用降低应用开发门槛实现与不同的轻松集成如果我的文章内容对你有所帮助请不要吝啬您的点赞收藏和关注期待你的一键三连咱们下个文章见',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2025-05-22 01:12:17',
  postMainColor: '##7E01FB',
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
      win.saveToLocal = {
        set: (key, value, ttl) => {
          if (ttl === 0) return
          const now = Date.now()
          const expiry = now + ttl * 86400000
          const item = {
            value,
            expiry
          }
          localStorage.setItem(key, JSON.stringify(item))
        },
      
        get: key => {
          const itemStr = localStorage.getItem(key)
      
          if (!itemStr) {
            return undefined
          }
          const item = JSON.parse(itemStr)
          const now = Date.now()
      
          if (now > item.expiry) {
            localStorage.removeItem(key)
            return undefined
          }
          return item.value
        }
      }
    
      win.getScript = (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        script.onerror = reject
        script.onload = script.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          script.onload = script.onreadystatechange = null
          resolve()
        }

        Object.keys(attr).forEach(key => {
          script.setAttribute(key, attr[key])
        })

        document.head.appendChild(script)
      })
    
      win.getCSS = (url, id = false) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onerror = reject
        link.onload = link.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          link.onload = link.onreadystatechange = null
          resolve()
        }
        document.head.appendChild(link)
      })
    
      win.activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#18171d')
        }
      }
      win.activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#f7f9fe')
        }
      }
      const t = saveToLocal.get('theme')
    
          const isDarkMode = window.matchMedia('(prefers-color-scheme: dark)').matches
          const isLightMode = window.matchMedia('(prefers-color-scheme: light)').matches
          const isNotSpecified = window.matchMedia('(prefers-color-scheme: no-preference)').matches
          const hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified

          if (t === undefined) {
            if (isLightMode) activateLightMode()
            else if (isDarkMode) activateDarkMode()
            else if (isNotSpecified || hasNoSupport) {
              const now = new Date()
              const hour = now.getHours()
              const isNight = hour <= 6 || hour >= 18
              isNight ? activateDarkMode() : activateLightMode()
            }
            window.matchMedia('(prefers-color-scheme: dark)').addListener(e => {
              if (saveToLocal.get('theme') === undefined) {
                e.matches ? activateDarkMode() : activateLightMode()
              }
            })
          } else if (t === 'light') activateLightMode()
          else activateDarkMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
      const detectApple = () => {
        if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
          document.documentElement.classList.add('apple')
        }
      }
      detectApple()
    })(window)</script><!-- 谷歌的html标记--><meta name="google-site-verification" content="填入相应码"><!-- 百度的html标记--><meta name="baidu-site-verification" content="codeva-vxWGXRA3Ih"><meta name="generator" content="Hexo 7.3.0"></head><body data-type="anzhiyu"><div id="web_bg"></div><div id="an_music_bg"></div><div id="loading-box" onclick="document.getElementById(&quot;loading-box&quot;).classList.add(&quot;loaded&quot;)"><div class="loading-bg"><img class="loading-img nolazyload" alt="加载头像" src="https://bu.dusays.com/2025/05/07/681b7b7d39a4b.jpeg"><div class="loading-image-dot"></div></div></div><script>const preloader = {
  endLoading: () => {
    document.getElementById('loading-box').classList.add("loaded");
  },
  initLoading: () => {
    document.getElementById('loading-box').classList.remove("loaded")
  }
}
window.addEventListener('load',()=> { preloader.endLoading() })
setTimeout(function(){preloader.endLoading();},10000)

if (true) {
  document.addEventListener('pjax:send', () => { preloader.initLoading() })
  document.addEventListener('pjax:complete', () => { preloader.endLoading() })
}</script><link rel="stylesheet" href="https://cdn.cbd.int/anzhiyu-theme-static@1.1.10/progress_bar/progress_bar.css"><script async="async" src="https://cdn.cbd.int/pace-js@1.2.4/pace.min.js" data-pace-options="{ &quot;restartOnRequestAfter&quot;:false,&quot;eventLag&quot;:false}"></script><div class="post" id="body-wrap"><header class="post-bg" id="page-header"><nav id="nav"><div id="nav-group"><span id="blog_name"><a id="site-name" href="/" accesskey="h"><div class="title">宋书生</div><i class="anzhiyufont anzhiyu-icon-house-chimney"></i></a><div id="he-plugin-simple"></div><script>var WIDGET = {
  "CONFIG": {
    "modules": "0124",
    "background": "2",
    "tmpColor": "FFFFFF",
    "tmpSize": "16",
    "cityColor": "FFFFFF",
    "citySize": "16",
    "aqiColor": "E8D87B",
    "aqiSize": "16",
    "weatherIconSize": "24",
    "alertIconSize": "18",
    "padding": "10px 10px 10px 10px",
    "shadow": "0",
    "language": "auto",
    "borderRadius": "20",
    "fixed": "true",
    "vertical": "top",
    "horizontal": "left",
    "left": "20",
    "top": "7.1",
    "key": "df245676fb434a0691ead1c63341cd94"
  }
}
</script><link rel="stylesheet" href="https://widget.qweather.net/simple/static/css/he-simple.css?v=1.4.0"><script src="https://widget.qweather.net/simple/static/js/he-simple.js?v=1.4.0"></script></span><div class="mask-name-container"><div id="name-container"><a id="page-name" href="javascript:anzhiyu.scrollToDest(0, 500)">PAGE_NAME</a></div></div><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="javascript:void(0);"><span> 文章</span></a><ul class="menus_item_child"><li><a class="site-page child faa-parent animated-hover" href="/categories/"><i class="anzhiyufont anzhiyu-icon-shapes faa-tada" style="font-size: 0.9em;"></i><span> 分类</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/tags/"><i class="anzhiyufont anzhiyu-icon-tags faa-tada" style="font-size: 0.9em;"></i><span> 标签</span></a></li><li><a class="site-page child faa-parent animated-hover" href="javascript:toRandomPost()"><i class="anzhiyufont anzhiyu-icon-shoe-prints1 faa-tada" style="font-size: 0.9em;"></i><span> 随便逛逛</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><span> 我的</span></a><ul class="menus_item_child"><li><a class="site-page child faa-parent animated-hover" href="/music/"><i class="anzhiyufont anzhiyu-icon-music faa-tada" style="font-size: 0.9em;"></i><span> 音乐馆</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/album/"><i class="anzhiyufont anzhiyu-icon-images faa-tada" style="font-size: 0.9em;"></i><span> 相册集</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><span> 关于</span></a><ul class="menus_item_child"><li><a class="site-page child faa-parent animated-hover" href="/about/"><i class="anzhiyufont anzhiyu-icon-paper-plane faa-tada" style="font-size: 0.9em;"></i><span> 关于本人</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/essay/"><i class="anzhiyufont anzhiyu-icon-lightbulb faa-tada" style="font-size: 0.9em;"></i><span> 闲言碎语</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/comments/"><i class="anzhiyufont anzhiyu-icon-envelope faa-tada" style="font-size: 0.9em;"></i><span> 留言板</span></a></li></ul></div></div></div><div id="nav-right"><div class="nav-button only-home" id="travellings_button" title="随机访问一篇文章"><a class="site-page" onclick="toRandomPost()" title="随机访问一篇文章" href="javascript:void(0);" rel="external nofollow" data-pjax-state="external"><i class="anzhiyufont anzhiyu-icon-dice"></i></a></div><div class="nav-button" id="search-button" title="站内搜索"><a class="site-page social-icon search" href="javascript:void(0);" title="搜索🔍" accesskey="s"><i class="anzhiyufont anzhiyu-icon-magnifying-glass"></i><span> 搜索</span></a></div><input id="center-console" type="checkbox"><label class="widget" for="center-console" title="中控台" onclick="anzhiyu.switchConsole();"><i class="left"></i><i class="widget center"></i><i class="widget right"></i></label><div id="console"><div class="console-card-group-reward"><ul class="reward-all console-card"><li class="reward-item"><a href="https://bu.dusays.com/2025/05/07/681b7a765a34f.jpg" target="_blank"><img class="post-qr-code-img" alt="微信" src="https://bu.dusays.com/2025/05/07/681b7a765a34f.jpg"></a><div class="post-qr-code-desc">微信</div></li><li class="reward-item"><a href="https://bu.dusays.com/2025/05/07/681b7a765e52a.jpg" target="_blank"><img class="post-qr-code-img" alt="支付宝" src="https://bu.dusays.com/2025/05/07/681b7a765e52a.jpg"></a><div class="post-qr-code-desc">支付宝</div></li></ul></div><div class="console-card-group"><div class="console-card-group-left"><div class="console-card" id="card-newest-comments"><div class="card-content"><div class="author-content-item-tips">互动</div><span class="author-content-item-title"> 最新评论</span></div><div class="aside-list"><span>正在加载中...</span></div></div></div><div class="console-card-group-right"><div class="console-card tags"><div class="card-content"><div class="author-content-item-tips">兴趣点</div><span class="author-content-item-title">寻找你感兴趣的领域</span><div class="card-tags"><div class="item-headline"></div><div class="card-tag-cloud"><a href="/tags/AIGC/" style="font-size: 1.05rem;">AIGC<sup>1</sup></a><a href="/tags/Agent/" style="font-size: 1.05rem;">Agent<sup>1</sup></a><a href="/tags/Hexo/" style="font-size: 1.05rem;">Hexo<sup>1</sup></a><a href="/tags/Java/" style="font-size: 1.05rem;">Java<sup>2</sup></a><a href="/tags/LLM/" style="font-size: 1.05rem;">LLM<sup>2</sup></a><a href="/tags/LangChain/" style="font-size: 1.05rem;">LangChain<sup>1</sup></a><a href="/tags/Ollama/" style="font-size: 1.05rem;">Ollama<sup>1</sup></a><a href="/tags/Python/" style="font-size: 1.05rem;">Python<sup>1</sup></a><a href="/tags/RAG/" style="font-size: 1.05rem;">RAG<sup>1</sup></a><a href="/tags/%E5%9F%BA%E7%A1%80/" style="font-size: 1.05rem;">基础<sup>2</sup></a><a href="/tags/%E5%BA%95%E5%B1%82/" style="font-size: 1.05rem;">底层<sup>1</sup></a><a href="/tags/%E6%BA%90%E7%A0%81/" style="font-size: 1.05rem;">源码<sup>1</sup></a><a href="/tags/%E9%98%BF%E9%87%8C%E4%BA%91/" style="font-size: 1.05rem;">阿里云<sup>1</sup></a><a href="/tags/%E9%9D%A2%E8%AF%95%E9%A2%98/" style="font-size: 1.05rem;">面试题<sup>1</sup></a><a href="/tags/%E9%A1%B9%E7%9B%AE%E6%90%AD%E5%BB%BA/" style="font-size: 1.05rem;">项目搭建<sup>3</sup></a></div></div><hr></div></div><div class="console-card history"><div class="item-headline"><i class="anzhiyufont anzhiyu-icon-box-archiv"></i><span>文章</span></div><div class="card-archives"><div class="item-headline"><i class="anzhiyufont anzhiyu-icon-archive"></i><span>归档</span></div><ul class="card-archive-list"><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2025/05/"><span class="card-archive-list-date">五月 2025</span><div class="card-archive-list-count-group"><span class="card-archive-list-count">4</span><span>篇</span></div></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2024/11/"><span class="card-archive-list-date">十一月 2024</span><div class="card-archive-list-count-group"><span class="card-archive-list-count">2</span><span>篇</span></div></a></li></ul></div><hr></div></div></div><div class="button-group"><div class="console-btn-item"><a class="darkmode_switchbutton" title="显示模式切换" href="javascript:void(0);"><i class="anzhiyufont anzhiyu-icon-moon"></i></a></div><div class="console-btn-item" id="consoleHideAside" onclick="anzhiyu.hideAsideBtn()" title="边栏显示控制"><a class="asideSwitch"><i class="anzhiyufont anzhiyu-icon-arrows-left-right"></i></a></div><div class="console-btn-item on" id="consoleCommentBarrage" onclick="anzhiyu.switchCommentBarrage()" title="热评开关"><a class="commentBarrage"><i class="anzhiyufont anzhiyu-icon-message"></i></a></div><div class="console-btn-item" id="consoleMusic" onclick="anzhiyu.musicToggle()" title="音乐开关"><a class="music-switch"><i class="anzhiyufont anzhiyu-icon-music"></i></a></div></div><div class="console-mask" onclick="anzhiyu.hideConsole()" href="javascript:void(0);"></div></div><div class="nav-button" id="nav-totop"><a class="totopbtn" href="javascript:void(0);"><i class="anzhiyufont anzhiyu-icon-arrow-up"></i><span id="percent" onclick="anzhiyu.scrollToDest(0,500)">0</span></a></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);" title="切换"><i class="anzhiyufont anzhiyu-icon-bars"></i></a></div></div></div></nav><div id="post-info"><div id="post-firstinfo"><div class="meta-firstline"><a class="post-meta-original">原创</a><span class="post-meta-categories"><span class="post-meta-separator"></span><i class="anzhiyufont anzhiyu-icon-inbox post-meta-icon"></i><a class="post-meta-categories" href="/categories/AIGC/" itemprop="url">AIGC</a></span><span class="article-meta tags"><a class="article-meta__tags" href="/tags/AIGC/" tabindex="-1" itemprop="url"> <span> <i class="anzhiyufont anzhiyu-icon-hashtag"></i>AIGC</span></a><a class="article-meta__tags" href="/tags/Python/" tabindex="-1" itemprop="url"> <span> <i class="anzhiyufont anzhiyu-icon-hashtag"></i>Python</span></a><a class="article-meta__tags" href="/tags/LangChain/" tabindex="-1" itemprop="url"> <span> <i class="anzhiyufont anzhiyu-icon-hashtag"></i>LangChain</span></a></span></div></div><h1 class="post-title" itemprop="name headline">LangChain教程(一):提示词工程与任务编排</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="anzhiyufont anzhiyu-icon-calendar-days post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" itemprop="dateCreated datePublished" datetime="2025-05-21T01:44:45.000Z" title="发表于 2025-05-21 09:44:45">2025-05-21</time><span class="post-meta-separator"></span><i class="anzhiyufont anzhiyu-icon-history post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" itemprop="dateCreated datePublished" datetime="2025-05-21T17:12:17.708Z" title="更新于 2025-05-22 01:12:17">2025-05-22</time></span></div><div class="meta-secondline"><span class="post-meta-separator"></span><span class="post-meta-wordcount"><i class="anzhiyufont anzhiyu-icon-file-word post-meta-icon" title="文章字数"></i><span class="post-meta-label" title="文章字数">字数总计:</span><span class="word-count" title="文章字数">12.6k</span><span class="post-meta-separator"></span><i class="anzhiyufont anzhiyu-icon-clock post-meta-icon" title="阅读时长"></i><span class="post-meta-label" title="阅读时长">阅读时长:</span><span>48分钟</span></span><span class="post-meta-separator"></span><span class="post-meta-pv-cv" id="" data-flag-title="LangChain教程(一):提示词工程与任务编排"><i class="anzhiyufont anzhiyu-icon-fw-eye post-meta-icon"></i><span class="post-meta-label" title="阅读量">阅读量:</span><span id="busuanzi_value_page_pv"><i class="anzhiyufont anzhiyu-icon-spinner anzhiyu-spin"></i></span></span><span class="post-meta-separator">       </span><span class="post-meta-position" title="作者IP属地为杭州"><i class="anzhiyufont anzhiyu-icon-location-dot"></i>杭州</span></div></div></div><section class="main-hero-waves-area waves-area"><svg class="waves-svg" xmlns="http://www.w3.org/2000/svg" xlink="http://www.w3.org/1999/xlink" viewBox="0 24 150 28" preserveAspectRatio="none" shape-rendering="auto"><defs><path id="gentle-wave" d="M -160 44 c 30 0 58 -18 88 -18 s 58 18 88 18 s 58 -18 88 -18 s 58 18 88 18 v 44 h -352 Z"></path></defs><g class="parallax"><use href="#gentle-wave" x="48" y="0"></use><use href="#gentle-wave" x="48" y="3"></use><use href="#gentle-wave" x="48" y="5"></use><use href="#gentle-wave" x="48" y="7"></use></g></svg></section><div id="post-top-cover"><img class="nolazyload" id="post-top-bg" src="https://bu.dusays.com/2025/05/22/682e07ffea50a.png"></div></header><main id="blog-container"><div class="layout" id="content-inner"><div id="post"><div class="post-ai-description"><div class="ai-title"><i class="anzhiyufont anzhiyu-icon-bilibili"></i><div class="ai-title-text">AI-摘要</div><i class="anzhiyufont anzhiyu-icon-arrow-rotate-right"></i><i class="anzhiyufont anzhiyu-icon-circle-dot" title="朗读摘要"></i><div id="ai-tag">Tianli GPT</div></div><div class="ai-explanation">AI初始化中...</div><div class="ai-btn-box"><div class="ai-btn-item">介绍自己 🙈</div><div class="ai-btn-item">生成本文简介 👋</div><div class="ai-btn-item">推荐相关文章 📖</div><div class="ai-btn-item">前往主页 🏠</div><div class="ai-btn-item" id="go-tianli-blog">前往爱发电购买</div></div><script data-pjax="" src="/js/anzhiyu/ai_abstract.js"></script></div><article class="post-content" id="article-container" itemscope="" itemtype="https://blog.smallscholar.com/AIGC/langchainBasic/"><header><a class="post-meta-categories" href="/categories/AIGC/" itemprop="url">AIGC</a><a href="/tags/AIGC/" tabindex="-1" itemprop="url">AIGC</a><a href="/tags/Python/" tabindex="-1" itemprop="url">Python</a><a href="/tags/LangChain/" tabindex="-1" itemprop="url">LangChain</a><h1 id="CrawlerTitle" itemprop="name headline">LangChain教程(一):提示词工程与任务编排</h1><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">宋书生</span><time itemprop="dateCreated datePublished" datetime="2025-05-21T01:44:45.000Z" title="发表于 2025-05-21 09:44:45">2025-05-21</time><time itemprop="dateCreated datePublished" datetime="2025-05-21T17:12:17.708Z" title="更新于 2025-05-22 01:12:17">2025-05-22</time></header><div id="postchat_postcontent"><blockquote>
<p>前言：本文涉及到的所有代码均可从<a target="_blank" rel="noopener" href="https://github.com/songscholar/langchain-tutorial">LangChain教程</a>中获取</p>
</blockquote>
<h2 id="一、LangChain组件介绍与快速入门"><a href="#一、LangChain组件介绍与快速入门" class="headerlink" title="一、LangChain组件介绍与快速入门"></a>一、LangChain组件介绍与快速入门</h2><h3 id="1-Langchain简介"><a href="#1-Langchain简介" class="headerlink" title="1. Langchain简介"></a>1. Langchain简介</h3><p>LangChain 是一个开源的 Python AI 应用开发框架, 它提供了构建基于大模型的 AI 应用所需的模块和工具。通过 LangChain, 开发者可以轻松地与大型语言模型 (LLM) 集成, 完成文本生成、问答、翻译、对话等任务。LangChain 降低了 AI 应用开发的门槛, 让任何人都可以基于 LLM 构建属于自己的创意应用。</p>
<h3 id="2-LangChain-特性"><a href="#2-LangChain-特性" class="headerlink" title="2. LangChain 特性"></a>2. LangChain 特性</h3><p><strong>(1). LLM 和提示（Prompt）</strong></p>
<ul>
<li><strong>API 抽象与统一接口</strong><br>LangChain 通过 <code>Models</code> 组件（如 <code>LLMs</code>、<code>Chat Models</code>、<code>Embeddings Models</code>）为不同大模型（如 OpenAI、DeepSeek、阿里通义等）提供统一接口。开发者无需关心底层 API 差异，只需通过配置即可切换模型。例如，使用阿里通义模型时，只需设置 <code>DASHSCOPE_API_KEY</code> 并调用 <code>ChatTongyi</code> 类。</li>
<li><strong>Prompt 模板管理</strong><br>LangChain 的 <code>PromptTemplate</code> 支持动态变量插入与多模板组合。例如，通过 <code>PipelinePromptTemplate</code> 可将系统角色、示例对话和用户输入拼接为完整提示，提升代码复用性。此外，<code>ExampleSelectors</code> 会根据输入长度或语义相似度动态选择示例，优化 Token 使用。</li>
</ul>
<p><strong>(2). 链（Chain）</strong></p>
<ul>
<li><strong>预置链与自定义链</strong><br>LangChain 内置了常见的任务链（如问答链、摘要链），也支持通过 <code>BaseChain</code> 自定义逻辑。例如，<code>create_sql_query_chain</code> 可以将自然语言转换为 SQL 语句，再通过 <code>QuerySQLDataBaseTool</code> 执行查询，最终用自然语言解释结果。这种链式设计将复杂流程分解为可组合的步骤，适合构建端到端应用。</li>
<li><strong>链的灵活性</strong><br>开发者可通过 <code>SimpleSequentialChain</code> 串联多个链，每个步骤可使用不同模型或工具。例如，先调用 LLM 解析用户意图，再调用搜索 API 获取数据，最后生成响应。</li>
</ul>
<p><strong>(3). LCEL（LangChain Expression Language）</strong></p>
<ul>
<li><strong>工作流编排</strong><br>LCEL 通过声明式语法定义 AI 任务流程。例如，使用 <code>RunnablePassthrough</code> 传递上下文，结合 <code>|</code> 运算符连接组件（如提示模板、模型调用、输出解析器），实现流水线处理。LCEL 还支持异步、流式处理和错误重试等功能。</li>
</ul>
<p><strong>(4). 数据增强生成（RAG）</strong></p>
<ul>
<li><strong>解决 Token 限制与数据实时性</strong><br>LangChain 通过 <code>Document Loaders</code> 加载外部数据（如 PDF、网页），使用 <code>Text Splitters</code> 分割长文本，再通过 <code>Embeddings</code> 模型向量化后存入向量数据库（如 FAISS、Chroma）。查询时，检索相关段落注入提示词，增强模型回答的准确性与时效性。</li>
</ul>
<p><strong>(5). Agents</strong></p>
<ul>
<li><strong>LLM 作为决策引擎</strong><br>Agent 将 LLM 作为“大脑”，根据用户目标自主调用工具（如计算器、API、数据库）完成不同的工作。例如，Pandas Agent 可解析自然语言指令，生成 Pandas 代码操作 DataFrame，而 SQL Agent 能将“统计 7 月 APP 渠道访客数”的指令转换为 SQL 查询并执行。</li>
<li><strong>动态决策流程</strong><br>Agent 通过 <code>ReAct</code> 框架（Reasoning and Acting）循环执行“思考-行动-观察”步骤，直至完成任务。例如，用户提问“明天天气如何？”时，Agent 可能先调用天气 API，再结合结果生成回复。</li>
</ul>
<p><strong>(6). 模型记忆（Memory）</strong></p>
<ul>
<li><strong>上下文管理</strong><br>LangChain 提供多种记忆组件：<code>ConversationBufferMemory</code> 存储完整对话历史，<code>ConversationSummaryMemory</code> 压缩历史为摘要，<code>EntityMemory</code> 提取关键实体。这些组件可集成到链或 Agent 中，支持多轮对话场景。</li>
</ul>
<h3 id="3-LangChain-框架组成"><a href="#3-LangChain-框架组成" class="headerlink" title="3. LangChain 框架组成"></a>3. LangChain 框架组成</h3><p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://bu.dusays.com/2025/05/22/682e07f9a9064.png" alt="LangChain框架组成"></p>
<p>LangChain 框架由几个部分组成，包括</p>
<ul>
<li><strong>LangChain 库</strong>：Python 和 JavaScript 库。包含接口和集成多种组件的运行时基础，以及现成的链和代理的实现。</li>
<li><strong>LangChain 模板</strong>：Langchain 官方提供的一些 AI 任务模板。</li>
<li><strong>LangServe</strong>：通过 REST API 部署链，支持快速集成到现有系统。例如，将 SQL 查询链发布为 API，供前端调用。</li>
<li><strong>LangSmith</strong>：提供全生命周期管理，包括：调试时追踪链的执行步骤，生产环境监控性能与异常，还可以通过评估工具优化提示词。</li>
</ul>
<h3 id="4-LangChain-库-Libraries"><a href="#4-LangChain-库-Libraries" class="headerlink" title="4. LangChain 库 (Libraries)"></a>4. LangChain 库 (Libraries)</h3><p>LangChain 库本身由几个不同的包组成。</p>
<ul>
<li><p><strong>langchain-core</strong>：基础抽象和 LangChain 表达语言。</p>
</li>
<li><p><strong>langchain-community</strong>：第三方集成，主要包括 langchain 集成的第三方组件。</p>
</li>
<li><p><strong>langchain</strong>：主要包括链 (chain)、代理(agent) 和检索策略。</p>
</li>
</ul>
<h3 id="5-langchain-任务处理流程"><a href="#5-langchain-任务处理流程" class="headerlink" title="5. langchain 任务处理流程"></a>5. langchain 任务处理流程</h3><p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://bu.dusays.com/2025/05/22/682e08565bd7a.png" alt="LangChain处理流程"></p>
<p>如上图，langChain 提供一套提示词模板 (prompt template) 管理工具，负责处理提示词，然后传递给大模型处理，最后处理大模型返回的结果，LangChain 对大模型的封装主要包括 LLM 和 Chat Model 两种类型。</p>
<ul>
<li><p>LLM - 问答模型，模型接收一个文本输入，然后返回一个文本结果。</p>
</li>
<li><p>Chat Model - 对话模型，接收一组对话消息，然后返回对话消息，类似聊天消息一样。</p>
</li>
</ul>
<h3 id="6-LangChain核心概念"><a href="#6-LangChain核心概念" class="headerlink" title="6. LangChain核心概念"></a>6. LangChain核心概念</h3><ol>
<li><p><strong>LLMs</strong>：LangChain 封装的基础模型，模型接收一个文本输入，然后返回一个文本结果。</p>
</li>
<li><p><strong>Chat Models</strong>：聊天模型（或者成为对话模型），与 LLMs 不同，这些模型专为对话场景而设计。模型可以接收一组对话消息，然后返回对话消息，类似聊天消息一样。</p>
</li>
<li><p><strong>消息（Message）</strong>：指的是聊天模型（Chat Models）的消息内容，消息类型包括包括 HumanMessage、AIMessage、SystemMessage、FunctionMessage 和 ToolMessage 等多种类型的消息。</p>
</li>
<li><p><strong>提示 (prompts)</strong> ：LangChain 封装了一组专门用于提示词 (prompts) 管理的工具类，方便我们格式化提示词 (prompts) 内容。</p>
</li>
<li><p><strong>输出解析器 (Output Parsers)</strong> ：如上图介绍，Langchain 接受大模型 (llm) 返回的文本内容之后，可以使用专门的输出解析器对文本内容进行格式化，例如解析 json、或者将 llm 输出的内容转成 python 对象。</p>
</li>
<li><p><strong>Retrievers</strong> ：为方便我们将私有数据导入到大模型（LLM）, 提高模型回答问题的质量，LangChain 封装了检索框架 (Retrievers)，方便我们加载文档数据、切割文档数据、存储和检索文档数据。</p>
</li>
<li><p><strong>向量存储 (Vector stores)</strong> ：为支持私有数据的语义相似搜索，langchain 支持多种向量数据库。</p>
</li>
<li><p><strong>Agents</strong> ：智能体 (Agents)，通常指的是以大模型（LLM）作为决策引擎，根据用户输入的任务，自动调用外部系统、硬件设备共同完成用户的任务，是一种以大模型（LLM）为核心的应用设计模式。</p>
</li>
</ol>
<h3 id="7-LangChain应用场景"><a href="#7-LangChain应用场景" class="headerlink" title="7. LangChain应用场景"></a>7. LangChain应用场景</h3><ul>
<li><p>对话机器人: 构建智能的对话助手、客服机器人、聊天机器人等。</p>
</li>
<li><p>知识库问答: 结合知识图谱, 进行开放域问题的问答服务。</p>
</li>
<li><p>智能写作: 如文章写作、创意写作、文本摘要等</p>
</li>
</ul>
<h3 id="8-LangChain快速入门"><a href="#8-LangChain快速入门" class="headerlink" title="8. LangChain快速入门"></a>8. LangChain快速入门</h3><h5 id="安装LangChain"><a href="#安装LangChain" class="headerlink" title="安装LangChain"></a>安装LangChain</h5><p>我们可以使用Pip和Conda安装LangChain相关依赖。以下是LangChain相关库以及后续学习时所需要的依赖：</p>
<figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">pip install langchain</span><br><span class="line">pip install langchain-openai</span><br><span class="line">pip install langchain-community</span><br><span class="line">pip install chromadb</span><br><span class="line">pip install defusedxml</span><br><span class="line">pip install wikipedia</span><br><span class="line">pip install faiss-cpu</span><br><span class="line">pip install langchain_chroma</span><br><span class="line">pip install toml</span><br><span class="line">pip install streamlit==1.39.0</span><br><span class="line">pip install -U langgraph</span><br><span class="line">pip install python-dotenv</span><br></pre></td></tr></tbody></table></figure>

<h5 id="初始化模型"><a href="#初始化模型" class="headerlink" title="初始化模型"></a>初始化模型</h5><p>在使用LangChain之前，需要导入LangChain x OpenAI集成包，并设置deepseek的API密钥作为环境变量或直接传递给OpenAI LLM类。</p>
<p>首先，我们需要先获取deepseek密钥，可以通过创建账户并访问<a target="_blank" rel="noopener" href="https://api-docs.deepseek.com/zh-cn/">此链接</a>来获取。然后，可以将API密钥设置为环境变量，方法如下，首先在项目的<strong>根目录</strong>中创建.env文件，然后添加如下信息：</p>
<figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">DEEPSEEK_API_KEY=your_api_key</span><br><span class="line">DEEPSEEK_BASE_URL=https://api.deepseek.com</span><br></pre></td></tr></tbody></table></figure>

<p>接下来，初始化模型：</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> dotenv <span class="keyword">import</span> load_dotenv</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> langchain_openai <span class="keyword">import</span> ChatOpenAI</span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载 .env 文件中的环境变量</span></span><br><span class="line">load_dotenv()</span><br><span class="line"></span><br><span class="line">llm = ChatOpenAI(</span><br><span class="line">    model=<span class="string">'deepseek-chat'</span>,</span><br><span class="line">    max_tokens=<span class="number">1024</span>,</span><br><span class="line">    api_key=os.getenv(<span class="string">"DEEPSEEK_API_KEY"</span>),</span><br><span class="line">    base_url=os.getenv(<span class="string">"DEEPSEEK_BASE_URL"</span>)</span><br><span class="line">)</span><br></pre></td></tr></tbody></table></figure>

<h5 id="使用LLM"><a href="#使用LLM" class="headerlink" title="使用LLM"></a>使用LLM</h5><p>使用LLM来回答问题非常简单。可以直接调用LLM的<code>invoke</code>方法，并传入问题作为参数。此外，还可以通过提示模板(prompt template)生成提示词，用于向模型(LLM)发送指令。</p>
<p>下面演示了如何构建一个简单的LLM链(chains)：</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain_core.prompts <span class="keyword">import</span> ChatPromptTemplate</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建一个提示模板(prompt template)</span></span><br><span class="line"><span class="comment"># 这里以对话模型的消息格式为例子，不熟悉openai对话模型消息格式，建议先学习OpenAI的API教程</span></span><br><span class="line"><span class="comment"># 下面消息模板，定义两条消息，system消息告诉模型扮演什么角色，user消息代表用户输入的问题，这里用了一个占位符{input} 代表接受一个模版参数input。</span></span><br><span class="line">prompt = ChatPromptTemplate.from_messages([</span><br><span class="line">    (<span class="string">"system"</span>, <span class="string">"你是一个著名的宋词研究学者"</span>),</span><br><span class="line">    (<span class="string">"user"</span>, <span class="string">"{input}"</span>)</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 基于LCEL 表达式构建LLM链，lcel语法类似linux的pipeline语法，从左到右按顺序执行</span></span><br><span class="line"><span class="comment"># 下面编排了一个简单的工作流，首先执行prompt完成提示词模板(prompt template)格式化处理， 然后将格式化后的prompt传递给llm模型执行，最终返回llm执行结果。</span></span><br><span class="line">chain = prompt | llm</span><br><span class="line"></span><br><span class="line"><span class="comment"># 调用LLM链并设置模板参数input,  invoke会把调用参数传递给prompt提示模板，开始chain定义的步骤开始逐步执行。</span></span><br><span class="line">result = chain.invoke({<span class="string">"input"</span>: <span class="string">"以怀才不遇，壮志难酬为主题写一首词牌名为”水调歌头“的词"</span>})</span><br><span class="line"><span class="built_in">print</span>(result)</span><br></pre></td></tr></tbody></table></figure>

<p>模型响应如下，可见deepseek相较于国产的其他模型来说还是非常强大的：</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">content=<span class="string">'《水调歌头·书愤》\n\n长剑倚天啸，孤影立寒秋。\n十年磨尽霜刃，空负少年头。\n欲挽银河洗甲，却叹冯唐易老，壮志几时酬？\n醉眼望星斗，清泪落吴钩。\n\n匣中鸣，弦上恨，总难休。\n男儿意气，何日能破玉门囚？\n纵使封侯无分，也要昆仑勒石，浩气贯神州。\n莫道书生拙，风雨会中流。'</span> additional_kwargs={<span class="string">'refusal'</span>: <span class="literal">None</span>} response_metadata={<span class="string">'token_usage'</span>: {<span class="string">'completion_tokens'</span>: <span class="number">112</span>, <span class="string">'prompt_tokens'</span>: <span class="number">32</span>, <span class="string">'total_tokens'</span>: <span class="number">144</span>, <span class="string">'completion_tokens_details'</span>: <span class="literal">None</span>, <span class="string">'prompt_tokens_details'</span>: {<span class="string">'audio_tokens'</span>: <span class="literal">None</span>, <span class="string">'cached_tokens'</span>: <span class="number">0</span>}, <span class="string">'prompt_cache_hit_tokens'</span>: <span class="number">0</span>, <span class="string">'prompt_cache_miss_tokens'</span>: <span class="number">32</span>}, <span class="string">'model_name'</span>: <span class="string">'deepseek-chat'</span>, <span class="string">'system_fingerprint'</span>: <span class="string">'fp_3d5141a69a_prod0225'</span>, <span class="string">'id'</span>: <span class="string">'b097c427-a719-4deb-a642-ae719bc339a9'</span>, <span class="string">'finish_reason'</span>: <span class="string">'stop'</span>, <span class="string">'logprobs'</span>: <span class="literal">None</span>} <span class="built_in">id</span>=<span class="string">'run-6f7de997-5dc6-43d2-baa0-45924f48e226-0'</span> usage_metadata={<span class="string">'input_tokens'</span>: <span class="number">32</span>, <span class="string">'output_tokens'</span>: <span class="number">112</span>, <span class="string">'total_tokens'</span>: <span class="number">144</span>, <span class="string">'input_token_details'</span>: {<span class="string">'cache_read'</span>: <span class="number">0</span>}, <span class="string">'output_token_details'</span>: {}}</span><br></pre></td></tr></tbody></table></figure>

<h5 id="输出转换"><a href="#输出转换" class="headerlink" title="输出转换"></a>输出转换</h5><p>LLM的输出通常是一条消息，为了更方便处理结果，可以将消息转换为字符串。下面展示如何将LLM的输出消息转换为字符串：</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> dotenv <span class="keyword">import</span> load_dotenv</span><br><span class="line"><span class="comment"># 引入langchain聊天场景的提示词模版</span></span><br><span class="line"><span class="keyword">from</span> langchain_core.output_parsers <span class="keyword">import</span> StrOutputParser</span><br><span class="line"><span class="keyword">from</span> langchain_core.prompts <span class="keyword">import</span> ChatPromptTemplate</span><br><span class="line"><span class="keyword">from</span> langchain_openai <span class="keyword">import</span> ChatOpenAI</span><br><span class="line"></span><br><span class="line">load_dotenv()</span><br><span class="line"></span><br><span class="line">llm = ChatOpenAI(</span><br><span class="line">    model=<span class="string">'deepseek-chat'</span>,</span><br><span class="line">    max_tokens=<span class="number">1024</span>,</span><br><span class="line">    api_key=os.getenv(<span class="string">"DEEPSEEK_API_KEY"</span>),</span><br><span class="line">    base_url=os.getenv(<span class="string">"DEEPSEEK_BASE_URL"</span>)</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 根据message生成提示词模版</span></span><br><span class="line">prompt = ChatPromptTemplate.from_messages([</span><br><span class="line">    (<span class="string">"system"</span>, <span class="string">"你是一个著名的宋词研究学者"</span>),</span><br><span class="line">    (<span class="string">"user"</span>, <span class="string">"{input}"</span>)</span><br><span class="line">])</span><br><span class="line"><span class="comment"># 创建一个字符串输出解析器</span></span><br><span class="line">output_parser = StrOutputParser()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 通过langchain的链式调用，生成一个chain</span></span><br><span class="line">chain = prompt | llm | output_parser</span><br><span class="line"></span><br><span class="line">result = chain.invoke({<span class="string">"input"</span>: <span class="string">"以怀才不遇，壮志难酬为主题写一首词牌名为”水调歌头“的词"</span>})</span><br><span class="line"><span class="built_in">print</span>(result)</span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">《水调歌头·书愤》</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">长剑倚天啸，孤影对残灯。</span></span><br><span class="line"><span class="string">十年磨就霜刃，无处试锋棱。</span></span><br><span class="line"><span class="string">欲驾长鲸碧海，却困蓬蒿荻苇，</span></span><br><span class="line"><span class="string">风雨暗相惊。</span></span><br><span class="line"><span class="string">醉眼挑灯看，匣底作龙鸣。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">射斗牛，光焰动，为谁明？</span></span><br><span class="line"><span class="string">男儿意气，空负燕颔虎头形。</span></span><br><span class="line"><span class="string">纵使封侯有骨，无奈时乖命蹇，</span></span><br><span class="line"><span class="string">白发已丛生。</span></span><br><span class="line"><span class="string">且尽杯中物，卧听晚潮声。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">注：本词通过"长剑"、"霜刃"等意象，表现志士的英武气概；以"困蓬蒿"、"白发丛生"等语，道出英雄失路的悲愤。下阕连用"射斗牛"、"燕颔虎头"典故，强化怀才不遇主题。结句"卧听晚潮"以景结情，留下苍凉余韵。全词跌宕起伏，符合词牌声情特点。</span></span><br><span class="line"><span class="string">'''</span></span><br></pre></td></tr></tbody></table></figure>



<p>通过上面短短十几行的代码我们就可以利用LangChain框架让大模型给我们“打工了”，可见解决Langchain使用大模型还是非常简单的。</p>
<h2 id="二、LangChain提示词工程应用实践"><a href="#二、LangChain提示词工程应用实践" class="headerlink" title="二、LangChain提示词工程应用实践"></a>二、LangChain提示词工程应用实践</h2><h3 id="1-什么是提示词模板？"><a href="#1-什么是提示词模板？" class="headerlink" title="1. 什么是提示词模板？"></a>1. 什么是提示词模板？</h3><p>上面也有介绍，语言模型以文本作为输入 - 这个文本通常被称为提示词(prompt)。在开发过程中，对于提示词通常不能直接硬编码，不利于提示词管理，而是通过提示词模板进行维护，类似开发过程中遇到的短信模板、邮件模板等等。提示词模板本质上跟平时大家使用的邮件模板、短信模板没什么区别，就是一个字符串模板，模板可以包含一组模板参数，通过改变参数值可以替换模板对应的参数。</p>
<p>一个提示词模板可以包含以下内容：</p>
<ul>
<li><p>发给大语言模型（LLM）的指令。</p>
</li>
<li><p>一组问答示例，以提醒AI以什么格式返回请求。</p>
</li>
<li><p>发给语言模型的问题。</p>
</li>
</ul>
<h3 id="2-如何创建提示词模板-prompt-template"><a href="#2-如何创建提示词模板-prompt-template" class="headerlink" title="2. 如何创建提示词模板(prompt template)"></a>2. 如何创建提示词模板(prompt template)</h3><h5 id="创建一个普通提示词模板"><a href="#创建一个普通提示词模板" class="headerlink" title="创建一个普通提示词模板"></a>创建一个普通提示词模板</h5><p>我们可以使用 <code>PromptTemplate</code> 类创建简单的提示词。提示词模板可以内嵌任意数量的模板参数，然后通过参数值格式化模板内容。</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain.prompts <span class="keyword">import</span> PromptTemplate</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义一个提示模板，包含adjective和content两个模板变量，模板变量使用{}包括起来</span></span><br><span class="line">prompt_template = PromptTemplate.from_template(</span><br><span class="line">    <span class="string">"给我讲一个关于{content}的{adjective}笑话。"</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 通过模板参数格式化提示模板</span></span><br><span class="line">result = prompt_template.<span class="built_in">format</span>(content=<span class="string">"书生求学"</span>, adjective=<span class="string">"冷"</span>)</span><br><span class="line"><span class="built_in">print</span>(result)</span><br></pre></td></tr></tbody></table></figure>

<p>模板输出结果：</p>
<figure class="highlight text"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">给我讲一个关于书生求学的冷笑话。</span><br></pre></td></tr></tbody></table></figure>

<h5 id="创建聊天消息提示词模板"><a href="#创建聊天消息提示词模板" class="headerlink" title="创建聊天消息提示词模板"></a>创建聊天消息提示词模板</h5><p>聊天模型（Chat Model）以聊天消息列表作为输入，这个聊天消息列表的消息内容也可以通过提示词模板进行管理。这些聊天消息与原始字符串不同，因为每个消息都与“角色(role)”相关联。</p>
<p>例如，在OpenAI的<a target="_blank" rel="noopener" href="https://platform.openai.com/docs/guides/text-generation/chat-completions-api">Chat Completion API</a>中，Openai的聊天模型，给不同的聊天消息定义了三种角色类型分别是助手(assistant)、人类（human）或系统（system）角色：</p>
<ul>
<li><p>助手(Assistant) 消息指的是当前消息是AI回答的内容</p>
</li>
<li><p>人类（user）消息指的是你发给AI的内容</p>
</li>
<li><p>系统（system）消息通常是用来给AI身份进行描述。</p>
</li>
</ul>
<p>创建聊天消息模板例子</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#导入langchain提示词模版库</span></span><br><span class="line"><span class="keyword">from</span> langchain_core.prompts <span class="keyword">import</span> ChatPromptTemplate</span><br><span class="line"></span><br><span class="line"><span class="comment"># 通过一个消息数组创建聊天消息模板</span></span><br><span class="line"><span class="comment"># 数组每一个元素代表一条消息，每个消息元组，第一个元素代表消息角色（也成为消息类型），第二个元素代表消息内容。</span></span><br><span class="line"><span class="comment"># 消息角色：system代表系统消息、human代表人类消息，ai代表LLM返回的消息内容</span></span><br><span class="line"><span class="comment"># 下面消息定义了2个模板参数name和user_input</span></span><br><span class="line">chat_template = ChatPromptTemplate.from_messages(</span><br><span class="line">    [</span><br><span class="line">        (<span class="string">"system"</span>, <span class="string">"你是一名人工智能助手，你的名字是{name}。"</span>),</span><br><span class="line">        (<span class="string">"human"</span>, <span class="string">"你好"</span>),</span><br><span class="line">        (<span class="string">"ai"</span>, <span class="string">"我很好，谢谢！"</span>),</span><br><span class="line">        (<span class="string">"human"</span>, <span class="string">"{user_input}"</span>),</span><br><span class="line">    ]</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 通过模板参数格式化模板内容</span></span><br><span class="line">messages = chat_template.format_messages(name=<span class="string">"SmallScholar"</span>, user_input=<span class="string">"你的名字叫什么？"</span>)</span><br><span class="line"><span class="built_in">print</span>(messages)</span><br><span class="line"><span class="comment"># [SystemMessage(content='你是一名人工智能助手，你的名字是SmallScholar。', additional_kwargs={}, response_metadata={}), HumanMessage(content='你好', additional_kwargs={}, response_metadata={}), AIMessage(content='我很好，谢谢！', additional_kwargs={}, response_metadata={}), HumanMessage(content='你的名字叫什么？', additional_kwargs={}, response_metadata={})]</span></span><br><span class="line"></span><br></pre></td></tr></tbody></table></figure>

<p>另外一种消息格式例子：</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain.prompts <span class="keyword">import</span> HumanMessagePromptTemplate</span><br><span class="line"><span class="keyword">from</span> langchain_core.messages <span class="keyword">import</span> SystemMessage</span><br><span class="line"><span class="keyword">from</span> langchain_core.prompts <span class="keyword">import</span> ChatPromptTemplate</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用langchain定义的SystemMessage、HumanMessagePromptTemplate等工具类定义消息，跟前面的例子类似，下面定义了两条消息</span></span><br><span class="line">chat_template = ChatPromptTemplate.from_messages(</span><br><span class="line">    [</span><br><span class="line">        SystemMessage(</span><br><span class="line">            content=(</span><br><span class="line">                <span class="string">"你是一个乐于助人的助手"</span></span><br><span class="line">            )</span><br><span class="line">        ),</span><br><span class="line">        HumanMessagePromptTemplate.from_template(<span class="string">"{text}"</span>),</span><br><span class="line">    ]</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用模板参数格式化模板</span></span><br><span class="line">messages = chat_template.format_messages(text=<span class="string">"书生喜欢古诗词"</span>)</span><br><span class="line"><span class="built_in">print</span>(messages)</span><br><span class="line"><span class="comment"># [SystemMessage(content='你是一个乐于助人的助手，可以润色内容，使其看起来起来更简单易读。', additional_kwargs={}, response_metadata={}), HumanMessage(content='我不喜欢吃好吃的东西', additional_kwargs={}, response_metadata={})]</span></span><br></pre></td></tr></tbody></table></figure>

<p>通常我们不会直接使用format_messages函数格式化提示模板(prompt templae)内容, 而是交给Langchain框架自动处理。</p>
<h5 id="在创建模板时使用MessagesPlaceholder"><a href="#在创建模板时使用MessagesPlaceholder" class="headerlink" title="在创建模板时使用MessagesPlaceholder"></a>在创建模板时使用MessagesPlaceholder</h5><p>这个提示模板负责在特定位置添加消息列表。 在上面的 ChatPromptTemplate 中，我们看到了如何格式化两条消息，每条消息都是一个字符串。 但是，如果我们希望用户传入一个消息列表，我们将其插入到特定位置，该怎么办？ 这就是 MessagesPlaceholder 的作用。</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain_core.prompts <span class="keyword">import</span> ChatPromptTemplate, MessagesPlaceholder</span><br><span class="line"><span class="keyword">from</span> langchain_core.messages <span class="keyword">import</span> HumanMessage, SystemMessage</span><br><span class="line"></span><br><span class="line">prompt_template = ChatPromptTemplate.from_messages([</span><br><span class="line">    (<span class="string">"system"</span>, <span class="string">"你是宋书生的人工智能助手"</span>),</span><br><span class="line">    <span class="comment">#可以传入一组消息</span></span><br><span class="line">    MessagesPlaceholder(<span class="string">"msgs"</span>)</span><br><span class="line">])</span><br><span class="line">result = prompt_template.invoke({<span class="string">"msgs"</span>: [HumanMessage(content=<span class="string">"你好!"</span>),HumanMessage(content=<span class="string">"你好，我是宋书生!"</span>)]})</span><br><span class="line"><span class="built_in">print</span>(result)</span><br><span class="line"><span class="comment">#messages=[SystemMessage(content='你是宋书生的人工智能助手', additional_kwargs={}, response_metadata={}), HumanMessage(content='你好!', additional_kwargs={}, response_metadata={}), HumanMessage(content='你好，我是宋书生!', additional_kwargs={}, response_metadata={})]</span></span><br></pre></td></tr></tbody></table></figure>

<p>以上代码将生成两条消息，第一条是系统消息，第二条是我们传入的 HumanMessage。 如果我们传入了 5 条消息，那么总共会生成 6 条消息（系统消息加上传入的 5 条消息）。 这对于将一系列消息插入到特定位置非常有用。 另一种实现相同效果的替代方法是，不直接使用 MessagesPlaceholder 类，而是：</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">prompt_template = ChatPromptTemplate.from_messages([</span><br><span class="line">    (<span class="string">"system"</span>, <span class="string">"你是宋书生的人工智能助手"</span>),</span><br><span class="line">    (<span class="string">"placeholder"</span>, <span class="string">"{msgs}"</span>) <span class="comment"># &lt;-- 这是更改的部分</span></span><br><span class="line">])</span><br></pre></td></tr></tbody></table></figure>

<h5 id="提示词追加示例"><a href="#提示词追加示例" class="headerlink" title="提示词追加示例"></a>提示词追加示例</h5><p>提示词中包含交互样本的作用是为了帮助模型更好地理解用户的意图，从而更好地回答问题或执行任务。小样本提示模板是指使用一组少量的示例来指导模型处理新的输入。这些示例可以用来训练模型，以便模型可以更好地理解和回答类似的问题。</p>
<p>例子：</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">Q: 什么是宋书生？</span><br><span class="line">A: 宋书生是一个励志成为精通LLM的愣头青。</span><br><span class="line"></span><br><span class="line">Q: 什么是宋铁柱？</span><br><span class="line">A: 未知。</span><br><span class="line"></span><br><span class="line">Q: 什么是语言模型？</span><br><span class="line">A:</span><br></pre></td></tr></tbody></table></figure>

<p>告诉模型根据，Q是问题，A是答案，按这种格式进行问答交互。</p>
<p>下面讲解的就是Lanchain针对在提示词中插入少量交互样本提供的工具类。</p>
<h3 id="3-使用示例集"><a href="#3-使用示例集" class="headerlink" title="3. 使用示例集"></a>3. 使用示例集</h3><h5 id="创建示例集"><a href="#创建示例集" class="headerlink" title="创建示例集"></a>创建示例集</h5><p>下面定义一个examples示例数组，里面包含一组问答样例。</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain.prompts.few_shot <span class="keyword">import</span> FewShotPromptTemplate</span><br><span class="line"><span class="keyword">from</span> langchain.prompts.prompt <span class="keyword">import</span> PromptTemplate</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">examples = [</span><br><span class="line">    {</span><br><span class="line">        <span class="string">"question"</span>: <span class="string">"珠穆朗玛峰和富士山哪一座山的首次登顶时间更早？"</span>,</span><br><span class="line">        <span class="string">"answer"</span>:</span><br><span class="line">            <span class="string">"""</span></span><br><span class="line"><span class="string">            这里需要跟进问题吗：是的。</span></span><br><span class="line"><span class="string">            跟进：珠穆朗玛峰的首次登顶时间是什么时候？</span></span><br><span class="line"><span class="string">            中间答案：珠穆朗玛峰于1953年5月29日首次被登顶。</span></span><br><span class="line"><span class="string">            跟进：富士山的首次登顶时间是什么时候？</span></span><br><span class="line"><span class="string">            中间答案：富士山在公元663年已有朝圣者登顶记录。</span></span><br><span class="line"><span class="string">            所以最终答案是：富士山</span></span><br><span class="line"><span class="string">            """</span></span><br><span class="line">    },</span><br><span class="line">    {</span><br><span class="line">        <span class="string">"question"</span>: <span class="string">"特斯拉和SpaceX的CEO是否曾就读于同一所大学？"</span>,</span><br><span class="line">        <span class="string">"answer"</span>:</span><br><span class="line">            <span class="string">"""</span></span><br><span class="line"><span class="string">            这里需要跟进问题吗：是的。</span></span><br><span class="line"><span class="string">            跟进：特斯拉的CEO是谁？</span></span><br><span class="line"><span class="string">            中间答案：特斯拉的CEO是Elon Musk。</span></span><br><span class="line"><span class="string">            跟进：Elon Musk曾就读于哪所大学？</span></span><br><span class="line"><span class="string">            中间答案：他曾在宾夕法尼亚大学学习。</span></span><br><span class="line"><span class="string">            跟进：SpaceX的CEO是谁？</span></span><br><span class="line"><span class="string">            中间答案：SpaceX的CEO也是Elon Musk。</span></span><br><span class="line"><span class="string">            所以最终答案是：是</span></span><br><span class="line"><span class="string">            """</span></span><br><span class="line">    },</span><br><span class="line">    {</span><br><span class="line">        <span class="string">"question"</span>: <span class="string">"《哈利波特》系列和《魔戒》系列的作者是否都出生于英国？"</span>,</span><br><span class="line">        <span class="string">"answer"</span>:</span><br><span class="line">            <span class="string">"""</span></span><br><span class="line"><span class="string">            这里需要跟进问题吗：是的。</span></span><br><span class="line"><span class="string">            跟进：《哈利波特》的作者是谁？</span></span><br><span class="line"><span class="string">            中间答案：J.K. Rowling。</span></span><br><span class="line"><span class="string">            跟进：J.K. Rowling的出生地是哪里？</span></span><br><span class="line"><span class="string">            中间答案：她出生于英国格洛斯特郡。</span></span><br><span class="line"><span class="string">            跟进：《魔戒》的作者是谁？</span></span><br><span class="line"><span class="string">            中间答案：J.R.R. Tolkien。</span></span><br><span class="line"><span class="string">            跟进：J.R.R. Tolkien的出生地是哪里？</span></span><br><span class="line"><span class="string">            中间答案：他出生于南非奥兰治自由邦。</span></span><br><span class="line"><span class="string">            所以最终答案是：不是</span></span><br><span class="line"><span class="string">            """</span></span><br><span class="line">    }</span><br><span class="line">]</span><br></pre></td></tr></tbody></table></figure>

<h5 id="创建小样本示例的格式化程序"><a href="#创建小样本示例的格式化程序" class="headerlink" title="创建小样本示例的格式化程序"></a>创建小样本示例的格式化程序</h5><p>通过PromptTemplate对象，我们可以非常简单的在提示词模板中插入样例。</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">example_prompt = PromptTemplate(input_variables=[<span class="string">"question"</span>, <span class="string">"answer"</span>], template=<span class="string">"问题：{question}\\n{answer}"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 提取examples示例集合的一个示例的内容，用于格式化模板内容</span></span><br><span class="line"><span class="built_in">print</span>(example_prompt.<span class="built_in">format</span>(**examples[<span class="number">0</span>]))</span><br></pre></td></tr></tbody></table></figure>

<p>返回：</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">问题：珠穆朗玛峰和富士山哪一座山的首次登顶时间更早？\n</span><br><span class="line">            这里需要跟进问题吗：是的。</span><br><span class="line">            跟进：珠穆朗玛峰的首次登顶时间是什么时候？</span><br><span class="line">            中间答案：珠穆朗玛峰于<span class="number">1953</span>年<span class="number">5</span>月<span class="number">29</span>日首次被登顶。</span><br><span class="line">            跟进：富士山的首次登顶时间是什么时候？</span><br><span class="line">            中间答案：富士山在公元<span class="number">663</span>年已有朝圣者登顶记录。</span><br><span class="line">            所以最终答案是：富士山</span><br></pre></td></tr></tbody></table></figure>

<h5 id="将示例和格式化程序提供给FewShotPromptTemplate"><a href="#将示例和格式化程序提供给FewShotPromptTemplate" class="headerlink" title="将示例和格式化程序提供给FewShotPromptTemplate"></a>将示例和格式化程序提供给FewShotPromptTemplate</h5><p>通过<code>FewShotPromptTemplate</code>对象，批量插入示例内容。</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#接收examples示例数组参数，通过example_prompt提示词模板批量渲染示例内容</span></span><br><span class="line"><span class="comment">#suffix和input_variables参数用于在提示词模板最后追加内容， input_variables用于定义suffix中包含的模板参数</span></span><br><span class="line">prompt = FewShotPromptTemplate(</span><br><span class="line">    examples=examples,</span><br><span class="line">    example_prompt=example_prompt,</span><br><span class="line">    suffix=<span class="string">"问题：{input}"</span>,</span><br><span class="line">    input_variables=[<span class="string">"input"</span>]</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(prompt.<span class="built_in">format</span>(<span class="built_in">input</span>=<span class="string">"《魔戒》的作者是谁？"</span>))</span><br></pre></td></tr></tbody></table></figure>

<p>返回：</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">问题：珠穆朗玛峰和富士山哪一座山的首次登顶时间更早？\n</span><br><span class="line">            这里需要跟进问题吗：是的。</span><br><span class="line">            跟进：珠穆朗玛峰的首次登顶时间是什么时候？</span><br><span class="line">            中间答案：珠穆朗玛峰于<span class="number">1953</span>年<span class="number">5</span>月<span class="number">29</span>日首次被登顶。</span><br><span class="line">            跟进：富士山的首次登顶时间是什么时候？</span><br><span class="line">            中间答案：富士山在公元<span class="number">663</span>年已有朝圣者登顶记录。</span><br><span class="line">            所以最终答案是：富士山</span><br><span class="line">            </span><br><span class="line"></span><br><span class="line">问题：特斯拉和SpaceX的CEO是否曾就读于同一所大学？\n</span><br><span class="line">            这里需要跟进问题吗：是的。</span><br><span class="line">            跟进：特斯拉的CEO是谁？</span><br><span class="line">            中间答案：特斯拉的CEO是Elon Musk。</span><br><span class="line">            跟进：Elon Musk曾就读于哪所大学？</span><br><span class="line">            中间答案：他曾在宾夕法尼亚大学学习。</span><br><span class="line">            跟进：SpaceX的CEO是谁？</span><br><span class="line">            中间答案：SpaceX的CEO也是Elon Musk。</span><br><span class="line">            所以最终答案是：是</span><br><span class="line">            </span><br><span class="line"></span><br><span class="line">问题：《哈利波特》系列和《魔戒》系列的作者是否都出生于英国？\n</span><br><span class="line">            这里需要跟进问题吗：是的。</span><br><span class="line">            跟进：《哈利波特》的作者是谁？</span><br><span class="line">            中间答案：J.K. Rowling。</span><br><span class="line">            跟进：J.K. Rowling的出生地是哪里？</span><br><span class="line">            中间答案：她出生于英国格洛斯特郡。</span><br><span class="line">            跟进：《魔戒》的作者是谁？</span><br><span class="line">            中间答案：J.R.R. Tolkien。</span><br><span class="line">            跟进：J.R.R. Tolkien的出生地是哪里？</span><br><span class="line">            中间答案：他出生于南非奥兰治自由邦。</span><br><span class="line">            所以最终答案是：不是</span><br><span class="line">            </span><br><span class="line"></span><br><span class="line">问题：《魔戒》的作者是谁？</span><br></pre></td></tr></tbody></table></figure>

<h3 id="4-使用示例选择器"><a href="#4-使用示例选择器" class="headerlink" title="4. 使用示例选择器"></a>4. 使用示例选择器</h3><h5 id="将示例提供给ExampleSelector"><a href="#将示例提供给ExampleSelector" class="headerlink" title="将示例提供给ExampleSelector"></a>将示例提供给ExampleSelector</h5><p>这里重用前一部分中的示例集和提示词模板(prompt template)。但是，不会将示例直接提供给<code>FewShotPromptTemplate</code>对象，把全部示例插入到提示词中，而是将它们提供给一个<code>ExampleSelector</code>对象，插入部分示例。</p>
<p>这里我们使用SemanticSimilarityExampleSelector类。该类根据与输入的相似性选择小样本示例。它使用嵌入模型计算输入和小样本示例之间的相似性，然后使用向量数据库执行相似搜索，获取跟输入相似的示例。</p>
<p><strong>提示：</strong>这里涉及向量计算、向量数据库，在AI领域这两个主要用于数据相似度搜索，例如：查询相似文章内容、相似的图片、视频等等，这里使用了google的向量数据库Chroma以及阿里的embedding模型text-embedding-v3，目前先做了解，会在后面教程中详细介绍。</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain.prompts.example_selector <span class="keyword">import</span> SemanticSimilarityExampleSelector</span><br><span class="line"><span class="keyword">from</span> langchain_community.vectorstores <span class="keyword">import</span> Chroma</span><br><span class="line"><span class="keyword">from</span> langchain_openai <span class="keyword">import</span> DashScopeEmbeddings</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用阿里的embedding，使用语义相似性示例选择器</span></span><br><span class="line">example_selector = SemanticSimilarityExampleSelector.from_examples(</span><br><span class="line">    <span class="comment"># 这是可供选择的示例列表。</span></span><br><span class="line">    examples,</span><br><span class="line">    <span class="comment"># 这是用于生成嵌入的嵌入类，该嵌入用于衡量语义相似性。</span></span><br><span class="line">    DashScopeEmbeddings(</span><br><span class="line">        model=<span class="string">"text-embedding-v3"</span>,</span><br><span class="line">        <span class="comment"># other params...</span></span><br><span class="line">    ),</span><br><span class="line">    <span class="comment"># 这是用于存储嵌入和执行相似性搜索的VectorStore类。</span></span><br><span class="line">    Chroma,</span><br><span class="line">    <span class="comment"># 这是要生成的示例数。</span></span><br><span class="line">    k=<span class="number">1</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 选择与输入最相似的示例。</span></span><br><span class="line">question = <span class="string">"《哈利波特》的作者是哪个国家的?"</span></span><br><span class="line">selected_examples = example_selector.select_examples({<span class="string">"question"</span>: question})</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f"最相似的示例：<span class="subst">{question}</span>"</span>)</span><br><span class="line"><span class="keyword">for</span> example <span class="keyword">in</span> selected_examples:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">"\\n"</span>)</span><br><span class="line">    <span class="keyword">for</span> k, v <span class="keyword">in</span> example.items():</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f"<span class="subst">{k}</span>：<span class="subst">{v}</span>"</span>)</span><br></pre></td></tr></tbody></table></figure>

<p>这里匹配了跟问题相似的例子，下面是返回：</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">最相似的示例：《哈利波特》的作者是哪个国家的?</span><br><span class="line">\n</span><br><span class="line">answer：</span><br><span class="line">            这里需要跟进问题吗：是的。</span><br><span class="line">            跟进：《哈利波特》的作者是谁？</span><br><span class="line">            中间答案：J.K. Rowling。</span><br><span class="line">            跟进：J.K. Rowling的出生地是哪里？</span><br><span class="line">            中间答案：她出生于英国格洛斯特郡。</span><br><span class="line">            跟进：《魔戒》的作者是谁？</span><br><span class="line">            中间答案：J.R.R. Tolkien。</span><br><span class="line">            跟进：J.R.R. Tolkien的出生地是哪里？</span><br><span class="line">            中间答案：他出生于南非奥兰治自由邦。</span><br><span class="line">            所以最终答案是：不是</span><br><span class="line">            </span><br><span class="line">question：《哈利波特》系列和《魔戒》系列的作者是否都出生于英国？</span><br></pre></td></tr></tbody></table></figure>

<h5 id="将示例选择器提供给FewShotPromptTemplate"><a href="#将示例选择器提供给FewShotPromptTemplate" class="headerlink" title="将示例选择器提供给FewShotPromptTemplate"></a>将示例选择器提供给FewShotPromptTemplate</h5><p>最后，创建一个<code>FewShotPromptTemplate</code>对象。根据前面的example_selector示例选择器，选择一个跟问题相似的例子。</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 选择与输入最相似的示例。</span></span><br><span class="line">question = <span class="string">"珠穆朗玛峰的首次登山时间？"</span></span><br><span class="line">selected_examples = example_selector.select_examples({<span class="string">"question"</span>: question})</span><br><span class="line">example_prompt = PromptTemplate(input_variables=[<span class="string">"question"</span>, <span class="string">"answer"</span>], template=<span class="string">"问题：{question}\\n{answer}"</span>)</span><br><span class="line"></span><br><span class="line">prompt = FewShotPromptTemplate(</span><br><span class="line">    example_selector=example_selector,</span><br><span class="line">    example_prompt=example_prompt,</span><br><span class="line">    suffix=<span class="string">"问题：{input}"</span>,</span><br><span class="line">    input_variables=[<span class="string">"input"</span>]</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(prompt.<span class="built_in">format</span>(<span class="built_in">input</span>=<span class="string">"珠穆朗玛峰的首次登山时间？"</span>))</span><br></pre></td></tr></tbody></table></figure>

<p>返回：</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">问题：珠穆朗玛峰和富士山哪一座山的首次登顶时间更早？\n</span><br><span class="line">            这里需要跟进问题吗：是的。</span><br><span class="line">            跟进：珠穆朗玛峰的首次登顶时间是什么时候？</span><br><span class="line">            中间答案：珠穆朗玛峰于<span class="number">1953</span>年<span class="number">5</span>月<span class="number">29</span>日首次被登顶。</span><br><span class="line">            跟进：富士山的首次登顶时间是什么时候？</span><br><span class="line">            中间答案：富士山在公元<span class="number">663</span>年已有朝圣者登顶记录。</span><br><span class="line">            所以最终答案是：富士山</span><br><span class="line">            </span><br><span class="line"></span><br><span class="line">问题：珠穆朗玛峰的首次登山时间？</span><br></pre></td></tr></tbody></table></figure>



<p>通过上面的讲解大家可以发现，LangChain中的提示词模板使用起来简单又方便，我们仅需要少量的代码就可以显著的增强大模型在特定领域的能力，还是非常推荐大家在以后使用大模型或者进行AIGC开发时多多使用提示词工程，毕竟性价比贼高。</p>
<h2 id="三、LangChain工作流编排"><a href="#三、LangChain工作流编排" class="headerlink" title="三、LangChain工作流编排"></a>三、LangChain工作流编排</h2><h3 id="1-LCEL介绍"><a href="#1-LCEL介绍" class="headerlink" title="1. LCEL介绍"></a>1. LCEL介绍</h3><p>LCEL(LangChain Expression Language) 是一种强大的工作流编排工具，可以通过基本组件构建复杂任务链条(chain)，并支持诸如流式处理、并行处理和日志记录等开箱即用的功能。</p>
<p> LCEL 从一开始就被设计为<strong>支持将原型投入生产，无需更改代码</strong>，从最简单的“提示 + LLM”链到最复杂的链，甚至有人成功地在生产中运行了包含数百步的 LCEL 链。以下是你可能想要使用 LCEL 的一些原因：</p>
<ul>
<li><p><strong>一流的流式支持</strong>：通过 LCEL 构建的链式流程，能够实现<strong>首个标记极速响应</strong>（即从请求发出到获取第一个输出块的最小延迟）。对于支持流式处理的链，系统可直接将大模型生成的原始标记实时传输至流式解析器，最终输出速率与模型原生输出速率完全同步。这种机制尤其适合需要实时交互的场景（如对话式 AI）。</p>
</li>
<li><p><strong>异步支持</strong>：所有基于 LCEL 构建的链，均支持<strong>同步与异步双模式调用</strong>：</p>
<ul>
<li><strong>同步模式</strong>：适用于 Jupyter 等交互式开发环境，便于快速原型验证。</li>
<li><strong>异步模式</strong>：可无缝集成至 LangServe 服务端，实现高并发请求处理。<br>开发者可使用同一套代码完成从实验到生产的全流程，兼顾开发效率与线上性能。</li>
</ul>
</li>
<li><p><strong>优化的并行执行</strong>：LCEL 自动识别链中可并行化的环节（例如同时从多个检索器获取文档），并在<strong>同步/异步接口中自动启用并行执行</strong>，最大限度降低整体延迟。此特性在复杂工作流中可提升 30%-50% 的吞吐效率。</p>
</li>
<li><p><strong>重试和回退：</strong> </p>
<ul>
<li><strong>重试与回退策略</strong>：可为链的任意环节配置自动重试规则和备用降级方案，显著增强系统在规模化场景下的鲁棒性。</li>
<li><strong>流式兼容性</strong>（开发中）：未来版本将支持重试操作与流式输出的无缝结合，实现可靠性提升与零延迟代价的兼得。</li>
</ul>
</li>
<li><p><strong>访问中间结果：</strong> 在复杂链执行过程中，开发者可<strong>实时获取中间步骤的结果流</strong>。此功能既可用于终端用户的状态提示（如显示“正在检索文档”），也能辅助开发阶段的调试追踪。该特性已全面支持 LangServe 服务端。 </p>
</li>
<li><p><strong>输入和输出模式：</strong> LCEL 为每个链自动生成<strong>基于 Pydantic 和 JSONSchema 的数据契约</strong>：</p>
<ul>
<li><strong>输入校验</strong>：拒绝不符合模式的非法请求。</li>
<li><strong>输出标准化</strong>：确保响应结构符合预期，降低下游系统集成成本。<br>此特性是 LangServe API 服务的核心基础，也是构建企业级应用的关键保障。</li>
</ul>
</li>
</ul>
<h3 id="2-Runable-interface介绍"><a href="#2-Runable-interface介绍" class="headerlink" title="2. Runable interface介绍"></a>2. Runable interface介绍</h3><p>LangChain 通过 <strong>Runnable 协议</strong> 标准化组件交互接口，大幅降低自定义链开发复杂度。该协议覆盖以下核心组件：</p>
<ul>
<li><strong>基础模型</strong>：聊天模型 (Chat Models)、大语言模型 (LLMs)</li>
<li><strong>数据处理模块</strong>：输出解析器 (Output Parsers)、检索器 (Retrievers)</li>
<li><strong>模板工具</strong>：提示模板 (Prompt Templates)</li>
<li><strong>扩展组件</strong>：支持开发者自定义实现的任意可运行对象</li>
</ul>
<hr>
<p><strong>标准接口方法</strong></p>
<table>
<thead>
<tr>
<th align="left">方法</th>
<th align="left">功能描述</th>
<th align="left">适用场景</th>
</tr>
</thead>
<tbody><tr>
<td align="left"><strong><code>invoke</code></strong></td>
<td align="left">同步调用链，输入单个参数并返回完整结果</td>
<td align="left">简单请求的同步处理</td>
</tr>
<tr>
<td align="left"><strong><code>stream</code></strong></td>
<td align="left">流式传输响应数据块，逐块生成输出结果</td>
<td align="left">实时交互/长文本生成</td>
</tr>
<tr>
<td align="left"><strong><code>batch</code></strong></td>
<td align="left">批量处理输入列表，返回对应结果集合</td>
<td align="left">高吞吐批量任务</td>
</tr>
</tbody></table>
<p><strong>异步接口扩展</strong></p>
<p>为支持高并发场景，所有方法均提供异步版本，需配合 <code>asyncio</code> 使用：</p>
<table>
<thead>
<tr>
<th align="left">异步方法</th>
<th align="left">核心特性</th>
<th align="left">版本要求</th>
</tr>
</thead>
<tbody><tr>
<td align="left"><strong><code>ainvoke</code></strong></td>
<td align="left">异步单请求处理，非阻塞执行</td>
<td align="left">基础支持</td>
</tr>
<tr>
<td align="left"><strong><code>astream</code></strong></td>
<td align="left">异步流式输出，支持实时数据传输</td>
<td align="left">基础支持</td>
</tr>
<tr>
<td align="left"><strong><code>abatch</code></strong></td>
<td align="left">异步批量处理，优化资源利用率</td>
<td align="left">基础支持</td>
</tr>
<tr>
<td align="left"><strong><code>astream_log</code></strong></td>
<td align="left">流式返回中间过程日志及最终结果，实现执行过程可视化</td>
<td align="left">基础支持</td>
</tr>
<tr>
<td align="left"><strong><code>astream_events</code></strong></td>
<td align="left">Beta 级事件流接口，实时推送链执行事件（如工具调用、模型响应）</td>
<td align="left">langchain-core ≥0.1.1</td>
</tr>
</tbody></table>
<p> 其中<strong>输入类型</strong> 和 <strong>输出类型</strong> 因组件而异： </p>
<table>
<thead>
<tr>
<th>组件</th>
<th>输入类型</th>
<th>输出类型</th>
</tr>
</thead>
<tbody><tr>
<td>提示</td>
<td>字典</td>
<td>提示值</td>
</tr>
<tr>
<td>聊天模型</td>
<td>单个字符串、聊天消息列表或提示值</td>
<td>聊天消息</td>
</tr>
<tr>
<td>LLM</td>
<td>单个字符串、聊天消息列表或提示值</td>
<td>字符串</td>
</tr>
<tr>
<td>输出解析器</td>
<td>LLM 或聊天模型的输出</td>
<td>取决于解析器</td>
</tr>
<tr>
<td>检索器</td>
<td>单个字符串</td>
<td>文档列表</td>
</tr>
<tr>
<td>工具</td>
<td>单个字符串或字典，取决于工具</td>
<td>取决于工具</td>
</tr>
</tbody></table>
<p>所有实现 <code>Runnable</code> 接口的对象均通过以下机制确保数据规范性：</p>
<ul>
<li><p><strong>input_schema:</strong> 基于组件结构自动生成的 Pydantic 输入模型</p>
</li>
<li><p><strong>output_schema:</strong> 通过运行时类型推导生成的 Pydantic 输出模型</p>
</li>
</ul>
<p>流式处理能力是构建响应式 LLM 应用的关键，LangChain 通过统一接口实现全链路流式支持：如<a target="_blank" rel="noopener" href="http://www.aidoczh.com/langchain/v0.2/docs/concepts/#chat-models">聊天模型</a>、<a target="_blank" rel="noopener" href="http://www.aidoczh.com/langchain/v0.2/docs/concepts/#output-parsers">输出解析器</a>、<a target="_blank" rel="noopener" href="http://www.aidoczh.com/langchain/v0.2/docs/concepts/#prompt-templates">提示模板</a>、<a target="_blank" rel="noopener" href="http://www.aidoczh.com/langchain/v0.2/docs/concepts/#retrievers">检索器</a>和<a target="_blank" rel="noopener" href="http://www.aidoczh.com/langchain/v0.2/docs/concepts/#agents">代理</a>都实现了 LangChain <a target="_blank" rel="noopener" href="http://www.aidoczh.com/langchain/v0.2/docs/concepts/#interface">Runnable 接口</a>。 该接口提供了两种通用的流式内容方法：</p>
<ol>
<li><p>同步 <code>stream</code> 和异步 <code>astream</code>：流式传输链中最终输出的默认实现。</p>
</li>
<li><p>异步 <code>astream_events</code> 和异步 <code>astream_log</code>：前者为事件驱动流主要用途为实时监控、审计日志，后者为过程监控流主要用途为开发调试、用户进度提示。 接下来我们将学习这两种流式方法。</p>
</li>
</ol>
<h3 id="3-Stream-流"><a href="#3-Stream-流" class="headerlink" title="3. Stream(流)"></a>3. Stream(流)</h3><p>所有 Runnable 对象都实现了名为 <code>stream</code> 的同步方法和名为 <code>astream</code> 的异步方法。这两个方法旨在以数据块的形式流式传输最终输出，尽可能快地返回每个处理单元。流式传输的实现前提是程序中的所有处理步骤都支持流式输入处理，即能够逐个处理输入数据块并生成对应的输出块。处理复杂度根据场景不同存在差异，从简单的任务（如输出 LLM 生成的令牌）到复杂场景（如在完整生成 JSON 结果前流式传输部分内容）均有覆盖。让我们从 LLM 应用程序的核心组件开始探索——LLM 本身！</p>
<h5 id="LLM-和聊天模型"><a href="#LLM-和聊天模型" class="headerlink" title="LLM 和聊天模型"></a>LLM 和聊天模型</h5><p>大型语言模型及其聊天模型变体是构建 LLM 应用程序的主要性能瓶颈。大型语言模型生成完整响应通常需要数秒时间，远超保持应用响应性所需的 200-300 毫秒阈值。提升应用响应性的核心策略在于实时展示中间处理进度，即通过逐个令牌流式传输模型的输出。以下为聊天模型的流式传输示例演示：</p>
<p>让我们从同步 stream API 开始：</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">model = ChatOpenAI(</span><br><span class="line">    model=<span class="string">'deepseek-chat'</span>,</span><br><span class="line">    max_tokens=<span class="number">1024</span>,</span><br><span class="line">    api_key=os.getenv(<span class="string">"DEEPSEEK_API_KEY"</span>),</span><br><span class="line">    base_url=os.getenv(<span class="string">"DEEPSEEK_BASE_URL"</span>)</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">chunks = []</span><br><span class="line"><span class="keyword">for</span> chunk <span class="keyword">in</span> model.stream(<span class="string">"宋词的前身是什么？"</span>):</span><br><span class="line">    chunks.append(chunk)</span><br><span class="line">    <span class="built_in">print</span>(chunk.content, end=<span class="string">"|"</span>, flush=<span class="literal">True</span>)</span><br><span class="line">    </span><br><span class="line"></span><br></pre></td></tr></tbody></table></figure>

<p>如果你在异步环境中工作，可以考虑使用异步 <code>astream</code> API：</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">model = ChatOpenAI(</span><br><span class="line">    model=<span class="string">'deepseek-chat'</span>,</span><br><span class="line">    max_tokens=<span class="number">1024</span>,</span><br><span class="line">    api_key=os.getenv(<span class="string">"DEEPSEEK_API_KEY"</span>),</span><br><span class="line">    base_url=os.getenv(<span class="string">"DEEPSEEK_BASE_URL"</span>)</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 异步流处理</span></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">async_stream</span>():</span><br><span class="line">    chunks = []</span><br><span class="line">    <span class="keyword">async</span> <span class="keyword">for</span> chunk <span class="keyword">in</span> model.astream(<span class="string">"宋词的前身是什么？"</span>):</span><br><span class="line">        chunks.append(chunk)</span><br><span class="line">        <span class="comment"># 判断chunks长度为1的时候，打印chunks[0]</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(chunks) == <span class="number">2</span>:</span><br><span class="line">            <span class="built_in">print</span>(chunks[<span class="number">1</span>])</span><br><span class="line">        <span class="built_in">print</span>(chunk.content, end=<span class="string">"|"</span>, flush=<span class="literal">True</span>)</span><br><span class="line"><span class="comment"># 运行异步流处理</span></span><br><span class="line">asyncio.run(async_stream())</span><br></pre></td></tr></tbody></table></figure>

<p>让我们检查其中一个块：</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">chunks[<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">content=<span class="string">'宋'</span> additional_kwargs={} response_metadata={} <span class="built_in">id</span>=<span class="string">'run-4fb547d7-43ea-4c1d-88a4-f81c763e8f3e'</span></span><br></pre></td></tr></tbody></table></figure>

<p>可以得到了一个称为 AIMessageChunk 的东西。该块表示 AIMessage 的一部分。 消息块是可叠加的——可以简单地将它们相加以获得到目前为止的响应状态！</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">chunks[<span class="number">0</span>] + chunks[<span class="number">1</span>] + chunks[<span class="number">2</span>] + chunks[<span class="number">3</span>] + chunks[<span class="number">4</span>]</span><br><span class="line"></span><br><span class="line">content=<span class="string">'宋词的前身'</span> additional_kwargs={} response_metadata={} <span class="built_in">id</span>=<span class="string">'run-c1bfd630-ec2e-4bf8-8cb2-79287cdbdc59'</span></span><br></pre></td></tr></tbody></table></figure>

<h5 id="Chain-链"><a href="#Chain-链" class="headerlink" title="Chain(链)"></a>Chain(链)</h5><p>绝大多数 LLM 应用程序都包含多步骤操作流程，而非仅执行单一的语言模型调用。我们通过 LangChain 表达式语言 (LCEL) 构建一个基础处理链，该链整合提示模板、模型组件及解析器模块，并验证流式传输机制的有效性。采用 <a target="_blank" rel="noopener" href="https://api.python.langchain.com/en/latest/output_parsers/langchain_core.output_parsers.string.StrOutputParser.html">StrOutputParser</a> 进行模型输出解析。该解析器通过从 <code>AIMessageChunk</code> 中提取 <code>content</code> 字段内容，实现模型生成 token 的标准化输出。</p>
<p>LCEL 采用声明式编程范式，通过组合 LangChain 基础组件构建完整工作流程。基于 LCEL 创建的链自动支持 <code>stream</code> 与 <code>astream</code> 方法，天然具备最终输出的流式传输能力。值得注意的是，所有 LCEL 构建的链均完整实现了标准 Runnable 接口规范。</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">prompt = ChatPromptTemplate.from_template(<span class="string">"给我讲一个关于{topic}的笑话"</span>)</span><br><span class="line">model = ChatOpenAI(</span><br><span class="line">    model=<span class="string">'deepseek-chat'</span>,</span><br><span class="line">    max_tokens=<span class="number">1024</span>,</span><br><span class="line">    api_key=os.getenv(<span class="string">"DEEPSEEK_API_KEY"</span>),</span><br><span class="line">    base_url=os.getenv(<span class="string">"DEEPSEEK_BASE_URL"</span>)</span><br><span class="line">)</span><br><span class="line">parser = StrOutputParser()</span><br><span class="line">chain = prompt | model | parser</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">async_stream</span>():</span><br><span class="line">    <span class="keyword">async</span> <span class="keyword">for</span> chunk <span class="keyword">in</span> chain.astream({<span class="string">"topic"</span>: <span class="string">"工作"</span>}):</span><br><span class="line">        <span class="built_in">print</span>(chunk, end=<span class="string">"|"</span>, flush=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 运行异步流处理</span></span><br><span class="line">asyncio.run(async_stream())</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">|好的|！|这是一个|关于|工作的|经典|笑话|：</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">|---</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">|**|老板|**|：|我们|公司|崇尚|平等|，|在这里|没有|等级|观念|！|  </span></span><br><span class="line"><span class="string">|**|新|员工|**|：|太好了|！|那|我可以|直接|叫|你|名字|吗|？|  </span></span><br><span class="line"><span class="string">|**|老板|**|：|当然|可以|。|  </span></span><br><span class="line"><span class="string">|**|新|员工|**|：|好的|，|老王|。|  </span></span><br><span class="line"><span class="string">|**|老板|**|：|……|叫我|王|总|。|  </span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">|（|冷笑|话|Bonus|：|平等|的前提|是|“|总|”|得|有人|加班|。）|  </span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">|---|</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">|希望|让你|会|心|一笑|～| 😄||</span></span><br><span class="line"><span class="string">'''</span></span><br></pre></td></tr></tbody></table></figure>

<p>需特别指出，即使我们在上述处理链末端添加了 <code>parser</code> 解析器组件，仍能保持流式输出能力。解析器会对每个流式数据块进行即时处理。许多 LCEL 基础组件均原生支持这种<strong>增量式流式传递</strong>特性，极大提升了应用构建效率。</p>
<p>开发者可设计返回生成器的自定义函数，以此实现流式数据操作能力。需注意，部分可运行对象（如提示模板和聊天模型）因需聚合前序步骤的完整结果，无法处理独立数据块，此类组件将中断流式处理流程。</p>
<p>LangChain 表达式语言（LCEL）实现了链式架构与调用模式的解耦（如同步/异步、批处理/流式等）。对于无需复杂编排的场景，开发者仍可采用命令式编程范式：通过 <code>invoke</code>、<code>batch</code> 或 <code>stream</code> 方法调用各组件，将执行结果存入变量后传递至下游处理。</p>
<p><strong>使用输入流</strong></p>
<p>若需要实现 JSON 的增量流式解析，传统方案将面临技术挑战：直接使用 <code>json.loads</code> 解析不完整的 JSON 片段会因格式无效导致解析失败。表面上看，这似乎宣告了 JSON 流式解析的不可行性。</p>
<p>实际上，通过构建支持<strong>输入流处理</strong>的解析器，可实现”智能补全”机制：该解析器持续接收输入流片段，动态推测并补全 JSON 结构至有效状态。以下通过实际运行演示解析器的核心工作机制：</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line">model = ChatOpenAI(</span><br><span class="line">    model=<span class="string">'deepseek-chat'</span>,</span><br><span class="line">    max_tokens=<span class="number">1024</span>,</span><br><span class="line">    api_key=os.getenv(<span class="string">"DEEPSEEK_API_KEY"</span>),</span><br><span class="line">    base_url=os.getenv(<span class="string">"DEEPSEEK_BASE_URL"</span>)</span><br><span class="line">)</span><br><span class="line">chain = (</span><br><span class="line">        model | JsonOutputParser()</span><br><span class="line">    <span class="comment"># 由于Langchain旧版本中的一个错误，JsonOutputParser未能从某些模型中流式传输结果</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">async_stream</span>():</span><br><span class="line">    <span class="keyword">async</span> <span class="keyword">for</span> text <span class="keyword">in</span> chain.astream(</span><br><span class="line">            <span class="string">"以JSON 格式输出中国、美国和印度的国家及其人口列表。"</span></span><br><span class="line">            <span class="string">'使用一个带有“countries”外部键的字典，其中包含国家列表。'</span></span><br><span class="line">            <span class="string">"每个国家都应该有键`name`和`population`"</span></span><br><span class="line">    ):</span><br><span class="line">        <span class="built_in">print</span>(text, flush=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 运行异步流处理</span></span><br><span class="line">asyncio.run(async_stream())</span><br><span class="line">        </span><br><span class="line"><span class="comment"># 输出</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">{}</span></span><br><span class="line"><span class="string">{'countries': []}</span></span><br><span class="line"><span class="string">{'countries': [{}]}</span></span><br><span class="line"><span class="string">{'countries': [{'name': ''}]}</span></span><br><span class="line"><span class="string">{'countries': [{'name': '中国'}]}</span></span><br><span class="line"><span class="string">{'countries': [{'name': '中国', 'population': 141}]}</span></span><br><span class="line"><span class="string">{'countries': [{'name': '中国', 'population': 141175}]}</span></span><br><span class="line"><span class="string">{'countries': [{'name': '中国', 'population': 141175000}]}</span></span><br><span class="line"><span class="string">{'countries': [{'name': '中国', 'population': 1411750000}]}</span></span><br><span class="line"><span class="string">{'countries': [{'name': '中国', 'population': 1411750000}, {}]}</span></span><br><span class="line"><span class="string">{'countries': [{'name': '中国', 'population': 1411750000}, {'name': ''}]}</span></span><br><span class="line"><span class="string">{'countries': [{'name': '中国', 'population': 1411750000}, {'name': '美国'}]}</span></span><br><span class="line"><span class="string">{'countries': [{'name': '中国', 'population': 1411750000}, {'name': '美国', 'population': 331}]}</span></span><br><span class="line"><span class="string">{'countries': [{'name': '中国', 'population': 1411750000}, {'name': '美国', 'population': 331000}]}</span></span><br><span class="line"><span class="string">{'countries': [{'name': '中国', 'population': 1411750000}, {'name': '美国', 'population': 331000000}]}</span></span><br><span class="line"><span class="string">{'countries': [{'name': '中国', 'population': 1411750000}, {'name': '美国', 'population': 331000000}, {}]}</span></span><br><span class="line"><span class="string">{'countries': [{'name': '中国', 'population': 1411750000}, {'name': '美国', 'population': 331000000}, {'name': ''}]}</span></span><br><span class="line"><span class="string">{'countries': [{'name': '中国', 'population': 1411750000}, {'name': '美国', 'population': 331000000}, {'name': '印度'}]}</span></span><br><span class="line"><span class="string">{'countries': [{'name': '中国', 'population': 1411750000}, {'name': '美国', 'population': 331000000}, {'name': '印度', 'population': 138}]}</span></span><br><span class="line"><span class="string">{'countries': [{'name': '中国', 'population': 1411750000}, {'name': '美国', 'population': 331000000}, {'name': '印度', 'population': 138000}]}</span></span><br><span class="line"><span class="string">{'countries': [{'name': '中国', 'population': 1411750000}, {'name': '美国', 'population': 331000000}, {'name': '印度', 'population': 138000000}]}</span></span><br><span class="line"><span class="string">{'countries': [{'name': '中国', 'population': 1411750000}, {'name': '美国', 'population': 331000000}, {'name': '印度', 'population': 1380000000}]}</span></span><br><span class="line"><span class="string">'''</span></span><br></pre></td></tr></tbody></table></figure>

<h3 id="4-Stream-events-事件流"><a href="#4-Stream-events-事件流" class="headerlink" title="4. Stream events(事件流)"></a>4. Stream events(事件流)</h3><p>现在我们已经了解了<code>stream</code>和<code>astream</code>的工作原理，让我们进入事件流的世界。🏞️</p>
<p>事件流是一个beta API。这个API可能会根据用户反馈略微更改。</p>
<p>本指南演示了<code>V2</code> API，并且需要 langchain-core &gt;= 0.2。对于与旧版本 LangChain 兼容的V1 API，请参阅<a target="_blank" rel="noopener" href="https://python.langchain.com/v0.1/docs/expression_language/streaming/#using-stream-events">这里</a>。</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看langchain-core版本</span></span><br><span class="line"><span class="keyword">import</span> langchain_core</span><br><span class="line">langchain_core.__version__</span><br></pre></td></tr></tbody></table></figure>

<p>为确保 <code>astream_events</code> 的正常运行，需严格遵循以下实现原则：</p>
<ul>
<li><strong>异步优先</strong>：在代码架构中优先采用 <code>async</code> 异步编程模式</li>
<li><strong>回调传播</strong>：定义自定义函数/可运行对象时需确保回调函数的完整传递</li>
<li><strong>流式强制</strong>：未使用 LCEL 时，对 LLM 组件调用 <code>.astream()</code> 而非 <code>.ainvoke</code> 以激活流式令牌生成</li>
</ul>
<h5 id="事件参考"><a href="#事件参考" class="headerlink" title="事件参考"></a><strong>事件参考</strong></h5><p>下表列举不同可运行对象可能触发的事件类型：</p>
<p>当流式处理正确实现时，可运行对象的输入信息通常只能在输入流完全处理完成后确定。这意味着 <code>inputs</code> 字段通常仅出现在结束阶段事件中，而不会包含在开始阶段事件中。</p>
<table>
<thead>
<tr>
<th>事件</th>
<th>名称</th>
<th>块</th>
<th>输入</th>
<th>输出</th>
</tr>
</thead>
<tbody><tr>
<td>on_chat_model_start</td>
<td>[模型名称]</td>
<td></td>
<td>{“messages”: [[SystemMessage, HumanMessage]]}</td>
<td></td>
</tr>
<tr>
<td>on_chat_model_end</td>
<td>[模型名称]</td>
<td></td>
<td>{“messages”: [[SystemMessage, HumanMessage]]}</td>
<td>AIMessageChunk(content=”hello world”)</td>
</tr>
<tr>
<td>on_llm_start</td>
<td>[模型名称]</td>
<td></td>
<td>{‘input’: ‘hello’}</td>
<td></td>
</tr>
<tr>
<td>on_llm_stream</td>
<td>[模型名称]</td>
<td>‘Hello’</td>
<td></td>
<td></td>
</tr>
<tr>
<td>on_llm_end</td>
<td>[模型名称]</td>
<td></td>
<td>‘Hello human!’</td>
<td></td>
</tr>
<tr>
<td>on_chain_start</td>
<td>format_docs</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>on_chain_stream</td>
<td>format_docs</td>
<td>“hello world!, goodbye world!”</td>
<td></td>
<td></td>
</tr>
<tr>
<td>on_chain_end</td>
<td>format_docs</td>
<td></td>
<td>[Document(…)]</td>
<td>“hello world!, goodbye world!”</td>
</tr>
<tr>
<td>on_tool_start</td>
<td>some_tool</td>
<td></td>
<td>{“x”: 1, “y”: “2”}</td>
<td></td>
</tr>
<tr>
<td>on_tool_end</td>
<td>some_tool</td>
<td></td>
<td></td>
<td>{“x”: 1, “y”: “2”}</td>
</tr>
<tr>
<td>on_retriever_start</td>
<td>[检索器名称]</td>
<td></td>
<td>{“query”: “hello”}</td>
<td></td>
</tr>
<tr>
<td>on_retriever_end</td>
<td>[检索器名称]</td>
<td></td>
<td>{“query”: “hello”}</td>
<td>[Document(…), ..]</td>
</tr>
<tr>
<td>on_prompt_start</td>
<td>[模板名称]</td>
<td></td>
<td>{“question”: “hello”}</td>
<td></td>
</tr>
<tr>
<td>on_prompt_end</td>
<td>[模板名称]</td>
<td></td>
<td>{“question”: “hello”}</td>
<td>ChatPromptValue(messages: [SystemMessage, …])</td>
</tr>
</tbody></table>
<h5 id="聊天模型"><a href="#聊天模型" class="headerlink" title="聊天模型"></a>聊天模型</h5><p>首先让我们看一下聊天模型产生的事件。</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">model = ChatOpenAI(</span><br><span class="line">    model=<span class="string">'deepseek-chat'</span>,</span><br><span class="line">    max_tokens=<span class="number">1024</span>,</span><br><span class="line">    api_key=os.getenv(<span class="string">"DEEPSEEK_API_KEY"</span>),</span><br><span class="line">    base_url=os.getenv(<span class="string">"DEEPSEEK_BASE_URL"</span>)</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 异步流处理</span></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">async_stream</span>():</span><br><span class="line">    events = []</span><br><span class="line">    <span class="keyword">async</span> <span class="keyword">for</span> event <span class="keyword">in</span> model.astream_events(<span class="string">"hello"</span>, version=<span class="string">"v2"</span>):</span><br><span class="line">        events.append(event)</span><br><span class="line">    <span class="built_in">print</span>(events)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 运行异步流处理</span></span><br><span class="line">asyncio.run(async_stream())</span><br><span class="line"><span class="comment"># 输出</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">[{'event': 'on_chat_model_start', 'data': {'input': 'hello'}, 'name': 'ChatOpenAI', 'tags': [], 'run_id': 'd106e0f1-7079-4e3f-a65a-822856c9a661', 'metadata': {'ls_provider': 'openai', 'ls_model_name': 'deepseek-chat', 'ls_model_type': 'chat', 'ls_temperature': None, 'ls_max_tokens': 1024}, 'parent_ids': []}, {'event': 'on_chat_model_stream', 'run_id': 'd106e0f1-7079-4e3f-a65a-822856c9a661', 'name': 'ChatOpenAI', 'tags': [], 'metadata': {'ls_provider': 'openai', 'ls_model_name': 'deepseek-chat', 'ls_model_type': 'chat', 'ls_temperature': None, 'ls_max_tokens': 1024}, 'data': {'chunk': AIMessageChunk(content='', additional_kwargs={}, response_metadata={}, id='run-d106e0f1-7079-4e3f-a65a-822856c9a661')}, 'parent_ids': []}, {'event': 'on_chat_model_stream', 'run_id': 'd106e0f1-7079-4e3f-a65a-822856c9a661', 'name': 'ChatOpenAI', 'tags': [], 'metadata': {'ls_provider': 'openai', 'ls_model_name': 'deepseek-chat', 'ls_model_type': 'chat', 'ls_temperature': None, 'ls_max_tokens': 1024}, 'data': {'chunk': AIMessageChunk(content='Hello', additional_kwargs={}, response_metadata={}, id='run-d106e0f1-7079-4e3f-a65a-822856c9a661')}, 'parent_ids': []}, {'event': 'on_chat_model_stream', 'run_id': 'd106e0f1-7079-4e3f-a65a-822856c9a661', 'name': 'ChatOpenAI', 'tags': [], 'metadata': {'ls_provider': 'openai', 'ls_model_name': 'deepseek-chat', 'ls_model_type': 'chat', 'ls_temperature': None, 'ls_max_tokens': 1024}, 'data': {'chunk': AIMessageChunk(content='!', additional_kwargs={}, response_metadata={}, id='run-d106e0f1-7079-4e3f-a65a-822856c9a661')}, 'parent_ids': []}, {'event': 'on_chat_model_stream', 'run_id': 'd106e0f1-7079-4e3f-a65a-822856c9a661', 'name': 'ChatOpenAI', 'tags': [], 'metadata': {'ls_provider': 'openai', 'ls_model_name': 'deepseek-chat', 'ls_model_type': 'chat', 'ls_temperature': None, 'ls_max_tokens': 1024}, 'data': {'chunk': AIMessageChunk(content=' 😊', additional_kwargs={}, response_metadata={}, id='run-d106e0f1-7079-4e3f-a65a-822856c9a661')}, 'parent_ids': []}, {'event': 'on_chat_model_stream', 'run_id': 'd106e0f1-7079-4e3f-a65a-822856c9a661', 'name': 'ChatOpenAI', 'tags': [], 'metadata': {'ls_provider': 'openai', 'ls_model_name': 'deepseek-chat', 'ls_model_type': 'chat', 'ls_temperature': None, 'ls_max_tokens': 1024}, 'data': {'chunk': AIMessageChunk(content=' How', additional_kwargs={}, response_metadata={}, id='run-d106e0f1-7079-4e3f-a65a-822856c9a661')}, 'parent_ids': []}, {'event': 'on_chat_model_stream', 'run_id': 'd106e0f1-7079-4e3f-a65a-822856c9a661', 'name': 'ChatOpenAI', 'tags': [], 'metadata': {'ls_provider': 'openai', 'ls_model_name': 'deepseek-chat', 'ls_model_type': 'chat', 'ls_temperature': None, 'ls_max_tokens': 1024}, 'data': {'chunk': AIMessageChunk(content=' can', additional_kwargs={}, response_metadata={}, id='run-d106e0f1-7079-4e3f-a65a-822856c9a661')}, 'parent_ids': []}, {'event': 'on_chat_model_stream', 'run_id': 'd106e0f1-7079-4e3f-a65a-822856c9a661', 'name': 'ChatOpenAI', 'tags': [], 'metadata': {'ls_provider': 'openai', 'ls_model_name': 'deepseek-chat', 'ls_model_type': 'chat', 'ls_temperature': None, 'ls_max_tokens': 1024}, 'data': {'chunk': AIMessageChunk(content=' I', additional_kwargs={}, response_metadata={}, id='run-d106e0f1-7079-4e3f-a65a-822856c9a661')}, 'parent_ids': []}, {'event': 'on_chat_model_stream', 'run_id': 'd106e0f1-7079-4e3f-a65a-822856c9a661', 'name': 'ChatOpenAI', 'tags': [], 'metadata': {'ls_provider': 'openai', 'ls_model_name': 'deepseek-chat', 'ls_model_type': 'chat', 'ls_temperature': None, 'ls_max_tokens': 1024}, 'data': {'chunk': AIMessageChunk(content=' assist', additional_kwargs={}, response_metadata={}, id='run-d106e0f1-7079-4e3f-a65a-822856c9a661')}, 'parent_ids': []}, {'event': 'on_chat_model_stream', 'run_id': 'd106e0f1-7079-4e3f-a65a-822856c9a661', 'name': 'ChatOpenAI', 'tags': [], 'metadata': {'ls_provider': 'openai', 'ls_model_name': 'deepseek-chat', 'ls_model_type': 'chat', 'ls_temperature': None, 'ls_max_tokens': 1024}, 'data': {'chunk': AIMessageChunk(content=' you', additional_kwargs={}, response_metadata={}, id='run-d106e0f1-7079-4e3f-a65a-822856c9a661')}, 'parent_ids': []}, {'event': 'on_chat_model_stream', 'run_id': 'd106e0f1-7079-4e3f-a65a-822856c9a661', 'name': 'ChatOpenAI', 'tags': [], 'metadata': {'ls_provider': 'openai', 'ls_model_name': 'deepseek-chat', 'ls_model_type': 'chat', 'ls_temperature': None, 'ls_max_tokens': 1024}, 'data': {'chunk': AIMessageChunk(content=' today', additional_kwargs={}, response_metadata={}, id='run-d106e0f1-7079-4e3f-a65a-822856c9a661')}, 'parent_ids': []}, {'event': 'on_chat_model_stream', 'run_id': 'd106e0f1-7079-4e3f-a65a-822856c9a661', 'name': 'ChatOpenAI', 'tags': [], 'metadata': {'ls_provider': 'openai', 'ls_model_name': 'deepseek-chat', 'ls_model_type': 'chat', 'ls_temperature': None, 'ls_max_tokens': 1024}, 'data': {'chunk': AIMessageChunk(content='?', additional_kwargs={}, response_metadata={}, id='run-d106e0f1-7079-4e3f-a65a-822856c9a661')}, 'parent_ids': []}, {'event': 'on_chat_model_stream', 'run_id': 'd106e0f1-7079-4e3f-a65a-822856c9a661', 'name': 'ChatOpenAI', 'tags': [], 'metadata': {'ls_provider': 'openai', 'ls_model_name': 'deepseek-chat', 'ls_model_type': 'chat', 'ls_temperature': None, 'ls_max_tokens': 1024}, 'data': {'chunk': AIMessageChunk(content='', additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'model_name': 'deepseek-chat', 'system_fingerprint': 'fp_3d5141a69a_prod0225'}, id='run-d106e0f1-7079-4e3f-a65a-822856c9a661', usage_metadata={'input_tokens': 4, 'output_tokens': 11, 'total_tokens': 15, 'input_token_details': {'cache_read': 0}, 'output_token_details': {}})}, 'parent_ids': []}, {'event': 'on_chat_model_end', 'data': {'output': AIMessageChunk(content='Hello! 😊 How can I assist you today?', additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'model_name': 'deepseek-chat', 'system_fingerprint': 'fp_3d5141a69a_prod0225'}, id='run-d106e0f1-7079-4e3f-a65a-822856c9a661', usage_metadata={'input_tokens': 4, 'output_tokens': 11, 'total_tokens': 15, 'input_token_details': {'cache_read': 0}, 'output_token_details': {}})}, 'run_id': 'd106e0f1-7079-4e3f-a65a-822856c9a661', 'name': 'ChatOpenAI', 'tags': [], 'metadata': {'ls_provider': 'openai', 'ls_model_name': 'deepseek-chat', 'ls_model_type': 'chat', 'ls_temperature': None, 'ls_max_tokens': 1024}, 'parent_ids': []}]</span></span><br><span class="line"><span class="string">'''</span></span><br></pre></td></tr></tbody></table></figure>

<p>关于接口中 <code>version="v2"</code> 参数的技术注解：此为 <strong>Beta 版 API</strong>，其规范可能发生变更（实际已进行过多次调整）。版本参数的设置旨在最大限度降低代码兼容性风险，当前的设计旨在减少未来版本升级对现有代码的破坏性影响。<br>📌 注意：<code>v2</code> 版本仅支持 <code>langchain-core&gt;=0.2.0</code>，建议通过 <code>pip install langchain-core --upgrade</code> 更新依赖。</p>
<h2 id="四、结语"><a href="#四、结语" class="headerlink" title="四、结语"></a>四、结语</h2><p>LangChain 作为开源框架，通过模块化设计、灵活的链式调用（LCEL）和强大的工具集成能力，为开发者提供了构建大语言模型（LLM）应用的高效路径。其核心价值体现在：</p>
<ol>
<li><strong>技术整合</strong>：统一多种模型（如 GPT-4、DeepSeek等）的 API 接口，支持 RAG、Agents 等复杂场景，解决了 LLM 实时性与数据局限性的矛盾。</li>
<li><strong>工程化能力</strong>：通过 LangSmith 的监控调试、LangServe 的 API 部署，实现从开发到生产的全生命周期管理。</li>
<li><strong>生态扩展</strong>：活跃的社区与丰富的第三方集成（如向量数据库、文档加载器）降低了开发门槛，推动 AI 应用的快速迭代。</li>
</ol>
<p>本文介绍了LangChain的相关组件，特性，框架组成、核心概念等内容。此外，还着重介绍了提示词工程应用实践、工作流编排等内容，展示了如何使用 LangChain 降低 AI 应用开发门槛，实现与不同 LLM 的轻松集成。如果我的文章内容对你有所帮助，请 不要吝啬您的点赞、收藏和关注，期待你的“一键三连”，咱们下个文章见。</p>
</div></article><div class="post-copyright"><div class="copyright-cc-box"><i class="anzhiyufont anzhiyu-icon-copyright"></i></div><div class="post-copyright__author_box"><a class="post-copyright__author_img" target="_blank" rel="noopener" href="https://blog.anheyu.com/" title="头像"><img class="post-copyright__author_img_back" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://bu.dusays.com/2025/05/07/681b7b7d39a4b.jpeg" title="头像" alt="头像"><img class="post-copyright__author_img_front" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://bu.dusays.com/2025/05/07/681b7b7d39a4b.jpeg" title="头像" alt="头像"></a><div class="post-copyright__author_name">宋书生</div><div class="post-copyright__author_desc">热爱生活 享受生活</div></div><div class="post-copyright__post__info"><a class="post-copyright__original" title="该文章为原创文章，注意版权协议" href="https://blog.smallscholar.com/AIGC/langchainBasic/">原创</a><a class="post-copyright-title"><span onclick="rm.copyPageUrl('https://blog.smallscholar.com/AIGC/langchainBasic/')">LangChain教程(一):提示词工程与任务编排</span></a></div><div class="post-tools" id="post-tools"><div class="post-tools-left"><div class="rewardLeftButton"><div class="post-reward" onclick="anzhiyu.addRewardMask()"><div class="reward-button button--animated" title="赞赏作者"><i class="anzhiyufont anzhiyu-icon-hand-heart-fill"></i>打赏作者</div><div class="reward-main"><div class="reward-all"><span class="reward-title">感谢你赐予我前进的力量</span><ul class="reward-group"><li class="reward-item"><a href="https://bu.dusays.com/2025/05/07/681b7a765a34f.jpg" target="_blank"><img class="post-qr-code-img" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://bu.dusays.com/2025/05/07/681b7a765a34f.jpg" alt="微信"></a><div class="post-qr-code-desc">微信</div></li><li class="reward-item"><a href="https://bu.dusays.com/2025/05/07/681b7a765e52a.jpg" target="_blank"><img class="post-qr-code-img" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://bu.dusays.com/2025/05/07/681b7a765e52a.jpg" alt="支付宝"></a><div class="post-qr-code-desc">支付宝</div></li></ul><a class="reward-main-btn" href="/about/#about-reward" target="_blank"><div class="reward-text">赞赏者名单</div><div class="reward-dec">因为你们的支持让我意识到写文章的价值🙏</div></a></div></div></div><div id="quit-box" onclick="anzhiyu.removeRewardMask()" style="display: none"></div></div><div class="shareRight"><div class="share-link mobile"><div class="share-qrcode"><div class="share-button" title="使用手机访问这篇文章"><i class="anzhiyufont anzhiyu-icon-qrcode"></i></div><div class="share-main"><div class="share-main-all"><div id="qrcode" title="https://blog.smallscholar.com/AIGC/langchainBasic/"></div><div class="reward-dec">使用手机访问这篇文章</div></div></div></div></div><div class="share-link weibo"><a class="share-button" target="_blank" href="https://service.weibo.com/share/share.php?title=LangChain教程(一):提示词工程与任务编排&amp;url=https://blog.smallscholar.com/AIGC/langchainBasic/&amp;pic=https://bu.dusays.com/2025/05/22/682e07ffea50a.png" rel="external nofollow noreferrer noopener"><i class="anzhiyufont anzhiyu-icon-weibo"></i></a></div><script>function copyCurrentPageUrl() {
  var currentPageUrl = window.location.href;
  var input = document.createElement("input");
  input.setAttribute("value", currentPageUrl);
  document.body.appendChild(input);
  input.select();
  input.setSelectionRange(0, 99999);
  document.execCommand("copy");
  document.body.removeChild(input);
}</script><div class="share-link copyurl"><div class="share-button" id="post-share-url" title="复制链接" onclick="copyCurrentPageUrl()"><i class="anzhiyufont anzhiyu-icon-link"></i></div></div></div></div></div><div class="post-copyright__notice"><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://blog.smallscholar.com" target="_blank">宋书生</a>！</span></div></div><div class="post-tools-right"><div class="tag_share"><div class="post-meta__box"><div class="post-meta__box__category-list"><a class="post-meta__box__categoryes" href="/categories/AIGC/"><span class="categoryes-punctuation"> <i class="anzhiyufont anzhiyu-icon-inbox"></i></span>AIGC<span class="categoryesPageCount">1</span></a></div><div class="post-meta__box__tag-list"><a class="post-meta__box__tags" href="/tags/AIGC/"><span class="tags-punctuation"> <i class="anzhiyufont anzhiyu-icon-tag"></i></span>AIGC<span class="tagsPageCount">1</span></a><a class="post-meta__box__tags" href="/tags/Python/"><span class="tags-punctuation"> <i class="anzhiyufont anzhiyu-icon-tag"></i></span>Python<span class="tagsPageCount">1</span></a><a class="post-meta__box__tags" href="/tags/LangChain/"><span class="tags-punctuation"> <i class="anzhiyufont anzhiyu-icon-tag"></i></span>LangChain<span class="tagsPageCount">1</span></a></div></div><div class="post_share"><div class="social-share" data-image="https://bu.dusays.com/2025/05/22/682e07ffea50a.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.cbd.int/butterfly-extsrc@1.1.3/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.cbd.int/butterfly-extsrc@1.1.3/sharejs/dist/js/social-share.min.js" defer="defer"></script></div></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-full"><a href="/Project/buildRAGFlow/"><img class="prev-cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://bu.dusays.com/2025/05/19/682af22b89aea.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">Mac版RAGFlow部署手册</div></div></a></div></nav><hr><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="anzhiyufont anzhiyu-icon-comments"></i><span> 评论</span></div><div class="comment-randomInfo"><a onclick="anzhiyu.addRandomCommentInfo()" href="javascript:void(0)">匿名评论</a><a href="/privacy" style="margin-left: 4px">隐私政策</a></div><div class="comment-tips" id="comment-tips"><span>✅ 你无需删除空行，直接评论以获取最佳展示效果</span></div></div><div class="comment-wrap"><div><div id="twikoo-wrap"></div></div></div></div><div class="comment-barrage"></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="card-content"><div class="author-info-avatar"><img class="avatar-img" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://bu.dusays.com/2025/05/07/681b7b7d39a4b.jpeg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"></div><div class="author-info__description"><div style="line-height:1.38;margin:0.6rem 0;text-align:justify;color:rgba(255, 255, 255, 0.8);">欢迎来到我的频道，这里有关于<b style="color:#fff">AIGC、Java、Web</b>等相关问题的解答，还有<b style="color:#fff"></b>经典书籍和框架底层原理<b style="color:#fff">的分享</b>。</div><div style="line-height:1.38;margin:0.6rem 0;text-align:justify;color:rgba(255, 255, 255, 0.8);">希望你可以在这里找到对你有用的<b style="color:#fff">文章</b>和<b style="color:#fff">内容</b>。</div></div><div class="author-info__bottom-group"><a class="author-info__bottom-group-left" href="/"><h1 class="author-info__name">宋书生</h1><div class="author-info__desc">热爱生活 享受生活</div></a><div class="card-info-social-icons is-center"><a class="social-icon faa-parent animated-hover" href="https://github.com/songscholar" target="_blank" title="Github"><i class="anzhiyufont anzhiyu-icon-github"></i></a><a class="social-icon faa-parent animated-hover" href="https://space.bilibili.com/350666742" target="_blank" title="BiliBili"><i class="anzhiyufont anzhiyu-icon-bilibili"></i></a></div></div></div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="anzhiyufont anzhiyu-icon-bars"></i><span>文章目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%80%E3%80%81LangChain%E7%BB%84%E4%BB%B6%E4%BB%8B%E7%BB%8D%E4%B8%8E%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8"><span class="toc-number">1.</span> <span class="toc-text">一、LangChain组件介绍与快速入门</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-Langchain%E7%AE%80%E4%BB%8B"><span class="toc-number">1.1.</span> <span class="toc-text">1. Langchain简介</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-LangChain-%E7%89%B9%E6%80%A7"><span class="toc-number">1.2.</span> <span class="toc-text">2. LangChain 特性</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-LangChain-%E6%A1%86%E6%9E%B6%E7%BB%84%E6%88%90"><span class="toc-number">1.3.</span> <span class="toc-text">3. LangChain 框架组成</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-LangChain-%E5%BA%93-Libraries"><span class="toc-number">1.4.</span> <span class="toc-text">4. LangChain 库 (Libraries)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-langchain-%E4%BB%BB%E5%8A%A1%E5%A4%84%E7%90%86%E6%B5%81%E7%A8%8B"><span class="toc-number">1.5.</span> <span class="toc-text">5. langchain 任务处理流程</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#6-LangChain%E6%A0%B8%E5%BF%83%E6%A6%82%E5%BF%B5"><span class="toc-number">1.6.</span> <span class="toc-text">6. LangChain核心概念</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#7-LangChain%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF"><span class="toc-number">1.7.</span> <span class="toc-text">7. LangChain应用场景</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#8-LangChain%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8"><span class="toc-number">1.8.</span> <span class="toc-text">8. LangChain快速入门</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%AE%89%E8%A3%85LangChain"><span class="toc-number">1.8.0.1.</span> <span class="toc-text">安装LangChain</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%88%9D%E5%A7%8B%E5%8C%96%E6%A8%A1%E5%9E%8B"><span class="toc-number">1.8.0.2.</span> <span class="toc-text">初始化模型</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E4%BD%BF%E7%94%A8LLM"><span class="toc-number">1.8.0.3.</span> <span class="toc-text">使用LLM</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E8%BE%93%E5%87%BA%E8%BD%AC%E6%8D%A2"><span class="toc-number">1.8.0.4.</span> <span class="toc-text">输出转换</span></a></li></ol></li></ol></li></ol><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BA%8C%E3%80%81LangChain%E6%8F%90%E7%A4%BA%E8%AF%8D%E5%B7%A5%E7%A8%8B%E5%BA%94%E7%94%A8%E5%AE%9E%E8%B7%B5"><span class="toc-number">2.</span> <span class="toc-text">二、LangChain提示词工程应用实践</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E4%BB%80%E4%B9%88%E6%98%AF%E6%8F%90%E7%A4%BA%E8%AF%8D%E6%A8%A1%E6%9D%BF%EF%BC%9F"><span class="toc-number">2.1.</span> <span class="toc-text">1. 什么是提示词模板？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-%E5%A6%82%E4%BD%95%E5%88%9B%E5%BB%BA%E6%8F%90%E7%A4%BA%E8%AF%8D%E6%A8%A1%E6%9D%BF-prompt-template"><span class="toc-number">2.2.</span> <span class="toc-text">2. 如何创建提示词模板(prompt template)</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%88%9B%E5%BB%BA%E4%B8%80%E4%B8%AA%E6%99%AE%E9%80%9A%E6%8F%90%E7%A4%BA%E8%AF%8D%E6%A8%A1%E6%9D%BF"><span class="toc-number">2.2.0.1.</span> <span class="toc-text">创建一个普通提示词模板</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%88%9B%E5%BB%BA%E8%81%8A%E5%A4%A9%E6%B6%88%E6%81%AF%E6%8F%90%E7%A4%BA%E8%AF%8D%E6%A8%A1%E6%9D%BF"><span class="toc-number">2.2.0.2.</span> <span class="toc-text">创建聊天消息提示词模板</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%9C%A8%E5%88%9B%E5%BB%BA%E6%A8%A1%E6%9D%BF%E6%97%B6%E4%BD%BF%E7%94%A8MessagesPlaceholder"><span class="toc-number">2.2.0.3.</span> <span class="toc-text">在创建模板时使用MessagesPlaceholder</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%BF%BD%E5%8A%A0%E7%A4%BA%E4%BE%8B"><span class="toc-number">2.2.0.4.</span> <span class="toc-text">提示词追加示例</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-%E4%BD%BF%E7%94%A8%E7%A4%BA%E4%BE%8B%E9%9B%86"><span class="toc-number">2.3.</span> <span class="toc-text">3. 使用示例集</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%88%9B%E5%BB%BA%E7%A4%BA%E4%BE%8B%E9%9B%86"><span class="toc-number">2.3.0.1.</span> <span class="toc-text">创建示例集</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%88%9B%E5%BB%BA%E5%B0%8F%E6%A0%B7%E6%9C%AC%E7%A4%BA%E4%BE%8B%E7%9A%84%E6%A0%BC%E5%BC%8F%E5%8C%96%E7%A8%8B%E5%BA%8F"><span class="toc-number">2.3.0.2.</span> <span class="toc-text">创建小样本示例的格式化程序</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%B0%86%E7%A4%BA%E4%BE%8B%E5%92%8C%E6%A0%BC%E5%BC%8F%E5%8C%96%E7%A8%8B%E5%BA%8F%E6%8F%90%E4%BE%9B%E7%BB%99FewShotPromptTemplate"><span class="toc-number">2.3.0.3.</span> <span class="toc-text">将示例和格式化程序提供给FewShotPromptTemplate</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-%E4%BD%BF%E7%94%A8%E7%A4%BA%E4%BE%8B%E9%80%89%E6%8B%A9%E5%99%A8"><span class="toc-number">2.4.</span> <span class="toc-text">4. 使用示例选择器</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%B0%86%E7%A4%BA%E4%BE%8B%E6%8F%90%E4%BE%9B%E7%BB%99ExampleSelector"><span class="toc-number">2.4.0.1.</span> <span class="toc-text">将示例提供给ExampleSelector</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%B0%86%E7%A4%BA%E4%BE%8B%E9%80%89%E6%8B%A9%E5%99%A8%E6%8F%90%E4%BE%9B%E7%BB%99FewShotPromptTemplate"><span class="toc-number">2.4.0.2.</span> <span class="toc-text">将示例选择器提供给FewShotPromptTemplate</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%89%E3%80%81LangChain%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%BC%96%E6%8E%92"><span class="toc-number">3.</span> <span class="toc-text">三、LangChain工作流编排</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-LCEL%E4%BB%8B%E7%BB%8D"><span class="toc-number">3.1.</span> <span class="toc-text">1. LCEL介绍</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-Runable-interface%E4%BB%8B%E7%BB%8D"><span class="toc-number">3.2.</span> <span class="toc-text">2. Runable interface介绍</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-Stream-%E6%B5%81"><span class="toc-number">3.3.</span> <span class="toc-text">3. Stream(流)</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#LLM-%E5%92%8C%E8%81%8A%E5%A4%A9%E6%A8%A1%E5%9E%8B"><span class="toc-number">3.3.0.1.</span> <span class="toc-text">LLM 和聊天模型</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#Chain-%E9%93%BE"><span class="toc-number">3.3.0.2.</span> <span class="toc-text">Chain(链)</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-Stream-events-%E4%BA%8B%E4%BB%B6%E6%B5%81"><span class="toc-number">3.4.</span> <span class="toc-text">4. Stream events(事件流)</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E4%BA%8B%E4%BB%B6%E5%8F%82%E8%80%83"><span class="toc-number">3.4.0.1.</span> <span class="toc-text">事件参考</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E8%81%8A%E5%A4%A9%E6%A8%A1%E5%9E%8B"><span class="toc-number">3.4.0.2.</span> <span class="toc-text">聊天模型</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9B%9B%E3%80%81%E7%BB%93%E8%AF%AD"><span class="toc-number">4.</span> <span class="toc-text">四、结语</span></a></li></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="anzhiyufont anzhiyu-icon-history"></i><span>最近发布</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/AIGC/langchainBasic/" title="LangChain教程(一):提示词工程与任务编排"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://bu.dusays.com/2025/05/22/682e07ffea50a.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="LangChain教程(一):提示词工程与任务编排"></a><div class="content"><a class="title" href="/AIGC/langchainBasic/" title="LangChain教程(一):提示词工程与任务编排">LangChain教程(一):提示词工程与任务编排</a><time datetime="2025-05-21T01:44:45.000Z" title="发表于 2025-05-21 09:44:45">2025-05-21</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/Project/buildRAGFlow/" title="Mac版RAGFlow部署手册"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://bu.dusays.com/2025/05/19/682af22b89aea.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Mac版RAGFlow部署手册"></a><div class="content"><a class="title" href="/Project/buildRAGFlow/" title="Mac版RAGFlow部署手册">Mac版RAGFlow部署手册</a><time datetime="2025-05-19T07:31:21.000Z" title="发表于 2025-05-19 15:31:21">2025-05-19</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/Project/installOllama/" title="LLM的定制管家--Ollama"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://bu.dusays.com/2025/05/19/682a121c5f5ad.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="LLM的定制管家--Ollama"></a><div class="content"><a class="title" href="/Project/installOllama/" title="LLM的定制管家--Ollama">LLM的定制管家--Ollama</a><time datetime="2025-05-18T07:31:21.000Z" title="发表于 2025-05-18 15:31:21">2025-05-18</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/Project/buildingHexoBlog/" title="Hexo个人博客搭建及上线全流程"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://bu.dusays.com/2025/05/13/682355b679eac.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Hexo个人博客搭建及上线全流程"></a><div class="content"><a class="title" href="/Project/buildingHexoBlog/" title="Hexo个人博客搭建及上线全流程">Hexo个人博客搭建及上线全流程</a><time datetime="2025-05-13T07:31:21.000Z" title="发表于 2025-05-13 15:31:21">2025-05-13</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/Java/floatingPointNumberBaseConversion/" title="Java中浮点数的进制转换原理"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://bu.dusays.com/2025/05/13/68222883ade00.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Java中浮点数的进制转换原理"></a><div class="content"><a class="title" href="/Java/floatingPointNumberBaseConversion/" title="Java中浮点数的进制转换原理">Java中浮点数的进制转换原理</a><time datetime="2024-11-15T01:03:37.657Z" title="发表于 2024-11-15 09:03:37">2024-11-15</time></div></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div id="footer_deal"><a class="deal_link" href="/szq1232000@163.com" title="email"><i class="anzhiyufont anzhiyu-icon-envelope"></i></a><a class="deal_link" target="_blank" rel="noopener" href="https://weibo.com/u/1223178222" title="微博"><i class="anzhiyufont anzhiyu-icon-weibo"></i></a><a class="deal_link" target="_blank" rel="noopener" href="https://qm.qq.com/q/SElHGb7m0M" title="QQ"><i class="anzhiyufont anzhiyu-icon-qq"></i></a><img class="footer_mini_logo" title="返回顶部" alt="返回顶部" onclick="anzhiyu.scrollToDest(0, 500)" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://bu.dusays.com/2025/05/11/6820a3b56d0b4.gif" size="50px"><a class="deal_link" target="_blank" rel="noopener" href="https://github.com/songscholar" title="Github"><i class="anzhiyufont anzhiyu-icon-github"></i></a><a class="deal_link" target="_blank" rel="noopener" href="https://space.bilibili.com/350666742" title="Bilibili"><i class="anzhiyufont anzhiyu-icon-bilibili"></i></a><a class="deal_link" target="_blank" rel="noopener" href="https://v.douyin.com/fty_sZvJsJk/" title="抖音"><i class="anzhiyufont anzhiyu-icon-tiktok"></i></a></div><div id="anzhiyu-footer"><div class="footer-group"><div class="footer-title">服务</div><div class="footer-links"><a class="footer-item" title="51la统计" target="_blank" rel="noopener" href="https://v6.51.la/">51la统计</a><a class="footer-item" title="数据库" target="_blank" rel="noopener" href="https://www.mongodb.com">数据库</a><a class="footer-item" title="hexo部署" target="_blank" rel="noopener" href="https://github.com">hexo部署</a></div></div><div class="footer-group"><div class="footer-title">生活</div><div class="footer-links"><a class="footer-item" title="音乐" href="/music/">音乐</a><a class="footer-item" title="相册" href="/album/">相册</a><a class="footer-item" title="杂谈" href="/essay/">杂谈</a></div></div><div class="footer-group"><div class="footer-title">社交</div><div class="footer-links"><a class="footer-item" title="微信" target="_blank" rel="noopener" href="https://bu.dusays.com/2025/05/08/681b9d37d0782.jpg">微信</a><a class="footer-item" title="QQ" target="_blank" rel="noopener" href="https://qm.qq.com/q/SElHGb7m0M">QQ</a><a class="footer-item" title="抖音" target="_blank" rel="noopener" href="https://v.douyin.com/fty_sZvJsJk/">抖音</a></div></div><div class="footer-group"><div class="footer-title">便捷链接</div><div class="footer-links"><a class="footer-item" title="DeepSeek" target="_blank" rel="noopener" href="https://chat.deepseek.com/">DeepSeek</a><a class="footer-item" title="Google" target="_blank" rel="noopener" href="https://www.google.com/">Google</a><a class="footer-item" title="GitHub" target="_blank" rel="noopener" href="https://github.com/">GitHub</a></div></div></div></div></footer></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="sidebar-site-data site-data is-center"><a href="/archives/" title="archive"><div class="headline">文章</div><div class="length-num">6</div></a><a href="/tags/" title="tag"><div class="headline">标签</div><div class="length-num">15</div></a><a href="/categories/" title="category"><div class="headline">分类</div><div class="length-num">4</div></a></div><span class="sidebar-menu-item-title">功能</span><div class="sidebar-menu-item"><a class="darkmode_switchbutton menu-child" href="javascript:void(0);" title="显示模式"><i class="anzhiyufont anzhiyu-icon-circle-half-stroke"></i><span>显示模式</span></a></div><div class="back-menu-list-groups"><div class="back-menu-list-group"><div class="back-menu-list-title">网页</div><div class="back-menu-list"><a class="back-menu-item" target="_blank" rel="noopener" href="https://blog.anheyu.com/" title="博客"><img class="back-menu-item-icon" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/img/favicon.ico" alt="博客"><span class="back-menu-item-text">博客</span></a></div></div><div class="back-menu-list-group"><div class="back-menu-list-title">项目</div><div class="back-menu-list"><a class="back-menu-item" target="_blank" rel="noopener" href="https://image.anheyu.com/" title="安知鱼图床"><img class="back-menu-item-icon" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://image.anheyu.com/favicon.ico" alt="安知鱼图床"><span class="back-menu-item-text">安知鱼图床</span></a></div></div></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="javascript:void(0);"><span> 文章</span></a><ul class="menus_item_child"><li><a class="site-page child faa-parent animated-hover" href="/categories/"><i class="anzhiyufont anzhiyu-icon-shapes faa-tada" style="font-size: 0.9em;"></i><span> 分类</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/tags/"><i class="anzhiyufont anzhiyu-icon-tags faa-tada" style="font-size: 0.9em;"></i><span> 标签</span></a></li><li><a class="site-page child faa-parent animated-hover" href="javascript:toRandomPost()"><i class="anzhiyufont anzhiyu-icon-shoe-prints1 faa-tada" style="font-size: 0.9em;"></i><span> 随便逛逛</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><span> 我的</span></a><ul class="menus_item_child"><li><a class="site-page child faa-parent animated-hover" href="/music/"><i class="anzhiyufont anzhiyu-icon-music faa-tada" style="font-size: 0.9em;"></i><span> 音乐馆</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/album/"><i class="anzhiyufont anzhiyu-icon-images faa-tada" style="font-size: 0.9em;"></i><span> 相册集</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><span> 关于</span></a><ul class="menus_item_child"><li><a class="site-page child faa-parent animated-hover" href="/about/"><i class="anzhiyufont anzhiyu-icon-paper-plane faa-tada" style="font-size: 0.9em;"></i><span> 关于本人</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/essay/"><i class="anzhiyufont anzhiyu-icon-lightbulb faa-tada" style="font-size: 0.9em;"></i><span> 闲言碎语</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/comments/"><i class="anzhiyufont anzhiyu-icon-envelope faa-tada" style="font-size: 0.9em;"></i><span> 留言板</span></a></li></ul></div></div><span class="sidebar-menu-item-title">标签</span><div class="card-tags"><div class="item-headline"></div><div class="card-tag-cloud"><a href="/tags/AIGC/" style="font-size: 0.88rem;">AIGC<sup>1</sup></a><a href="/tags/Agent/" style="font-size: 0.88rem;">Agent<sup>1</sup></a><a href="/tags/Hexo/" style="font-size: 0.88rem;">Hexo<sup>1</sup></a><a href="/tags/Java/" style="font-size: 0.88rem;">Java<sup>2</sup></a><a href="/tags/LLM/" style="font-size: 0.88rem;">LLM<sup>2</sup></a><a href="/tags/LangChain/" style="font-size: 0.88rem;">LangChain<sup>1</sup></a><a href="/tags/Ollama/" style="font-size: 0.88rem;">Ollama<sup>1</sup></a><a href="/tags/Python/" style="font-size: 0.88rem;">Python<sup>1</sup></a><a href="/tags/RAG/" style="font-size: 0.88rem;">RAG<sup>1</sup></a><a href="/tags/%E5%9F%BA%E7%A1%80/" style="font-size: 0.88rem;">基础<sup>2</sup></a><a href="/tags/%E5%BA%95%E5%B1%82/" style="font-size: 0.88rem;">底层<sup>1</sup></a><a href="/tags/%E6%BA%90%E7%A0%81/" style="font-size: 0.88rem;">源码<sup>1</sup></a><a href="/tags/%E9%98%BF%E9%87%8C%E4%BA%91/" style="font-size: 0.88rem;">阿里云<sup>1</sup></a><a href="/tags/%E9%9D%A2%E8%AF%95%E9%A2%98/" style="font-size: 0.88rem;">面试题<sup>1</sup></a><a href="/tags/%E9%A1%B9%E7%9B%AE%E6%90%AD%E5%BB%BA/" style="font-size: 0.88rem;">项目搭建<sup>3</sup></a></div></div><hr></div></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="anzhiyufont anzhiyu-icon-book-open"></i></button><button id="translateLink" type="button" title="简繁转换">繁</button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="anzhiyufont anzhiyu-icon-circle-half-stroke"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="anzhiyufont anzhiyu-icon-arrows-left-right"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="anzhiyufont anzhiyu-icon-gear"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="anzhiyufont anzhiyu-icon-list-ul"></i></button><button id="chat-btn" type="button" title="聊天"><i class="anzhiyufont anzhiyu-icon-comment-sms"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="anzhiyufont anzhiyu-icon-comments"></i></a><a id="switch-commentBarrage" href="javascript:anzhiyu.switchCommentBarrage();" title="开关弹幕"><i class="anzhiyufont anzhiyu-icon-danmu"></i></a><button id="go-up" type="button" title="回到顶部"><i class="anzhiyufont anzhiyu-icon-arrow-up"></i></button></div></div><div id="nav-music"><a id="nav-music-hoverTips" onclick="anzhiyu.musicToggle()" accesskey="m">播放音乐</a><div id="console-music-bg"></div><meting-js id="9283434155" server="tencent" type="playlist" mutex="true" preload="none" theme="var(--anzhiyu-main)" data-lrctype="0" order="random" volume="0.7"></meting-js></div><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="anzhiyufont anzhiyu-icon-xmark"></i></button></nav><div class="is-center" id="loading-database"><i class="anzhiyufont anzhiyu-icon-spinner anzhiyu-pulse-icon"></i><span>  数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"></div></div><hr><div id="local-search-results"></div></div></div><div id="search-mask"></div></div><div id="rightMenu"><div class="rightMenu-group rightMenu-small"><div class="rightMenu-item" id="menu-backward"><i class="anzhiyufont anzhiyu-icon-arrow-left"></i></div><div class="rightMenu-item" id="menu-forward"><i class="anzhiyufont anzhiyu-icon-arrow-right"></i></div><div class="rightMenu-item" id="menu-refresh"><i class="anzhiyufont anzhiyu-icon-arrow-rotate-right" style="font-size: 1rem;"></i></div><div class="rightMenu-item" id="menu-top"><i class="anzhiyufont anzhiyu-icon-arrow-up"></i></div></div><div class="rightMenu-group rightMenu-line rightMenuPlugin"><div class="rightMenu-item" id="menu-copytext"><i class="anzhiyufont anzhiyu-icon-copy"></i><span>复制选中文本</span></div><div class="rightMenu-item" id="menu-pastetext"><i class="anzhiyufont anzhiyu-icon-paste"></i><span>粘贴文本</span></div><a class="rightMenu-item" id="menu-commenttext"><i class="anzhiyufont anzhiyu-icon-comment-medical"></i><span>引用到评论</span></a><div class="rightMenu-item" id="menu-newwindow"><i class="anzhiyufont anzhiyu-icon-window-restore"></i><span>新窗口打开</span></div><div class="rightMenu-item" id="menu-copylink"><i class="anzhiyufont anzhiyu-icon-link"></i><span>复制链接地址</span></div><div class="rightMenu-item" id="menu-copyimg"><i class="anzhiyufont anzhiyu-icon-images"></i><span>复制此图片</span></div><div class="rightMenu-item" id="menu-downloadimg"><i class="anzhiyufont anzhiyu-icon-download"></i><span>下载此图片</span></div><div class="rightMenu-item" id="menu-newwindowimg"><i class="anzhiyufont anzhiyu-icon-window-restore"></i><span>新窗口打开图片</span></div><div class="rightMenu-item" id="menu-search"><i class="anzhiyufont anzhiyu-icon-magnifying-glass"></i><span>站内搜索</span></div><div class="rightMenu-item" id="menu-searchBaidu"><i class="anzhiyufont anzhiyu-icon-magnifying-glass"></i><span>百度搜索</span></div><div class="rightMenu-item" id="menu-music-toggle"><i class="anzhiyufont anzhiyu-icon-play"></i><span>播放音乐</span></div><div class="rightMenu-item" id="menu-music-back"><i class="anzhiyufont anzhiyu-icon-backward"></i><span>切换到上一首</span></div><div class="rightMenu-item" id="menu-music-forward"><i class="anzhiyufont anzhiyu-icon-forward"></i><span>切换到下一首</span></div><div class="rightMenu-item" id="menu-music-playlist" onclick="window.open(&quot;https://y.qq.com/n/ryqq/playlist/9283434155&quot;, &quot;_blank&quot;);" style="display: none;"><i class="anzhiyufont anzhiyu-icon-radio"></i><span>查看所有歌曲</span></div><div class="rightMenu-item" id="menu-music-copyMusicName"><i class="anzhiyufont anzhiyu-icon-copy"></i><span>复制歌名</span></div></div><div class="rightMenu-group rightMenu-line rightMenuOther"><a class="rightMenu-item menu-link" id="menu-randomPost"><i class="anzhiyufont anzhiyu-icon-shuffle"></i><span>随便逛逛</span></a><a class="rightMenu-item menu-link" href="/categories/"><i class="anzhiyufont anzhiyu-icon-cube"></i><span>博客分类</span></a><a class="rightMenu-item menu-link" href="/tags/"><i class="anzhiyufont anzhiyu-icon-tags"></i><span>文章标签</span></a></div><div class="rightMenu-group rightMenu-line rightMenuOther"><a class="rightMenu-item" id="menu-copy" href="javascript:void(0);"><i class="anzhiyufont anzhiyu-icon-copy"></i><span>复制地址</span></a><a class="rightMenu-item" id="menu-commentBarrage" href="javascript:void(0);"><i class="anzhiyufont anzhiyu-icon-message"></i><span class="menu-commentBarrage-text">关闭热评</span></a><a class="rightMenu-item" id="menu-darkmode" href="javascript:void(0);"><i class="anzhiyufont anzhiyu-icon-circle-half-stroke"></i><span class="menu-darkmode-text">深色模式</span></a><a class="rightMenu-item" id="menu-translate" href="javascript:void(0);"><i class="anzhiyufont anzhiyu-icon-language"></i><span>轉為繁體</span></a></div></div><div id="rightmenu-mask"></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://cdn.cbd.int/@fancyapps/ui@5.0.28/dist/fancybox/fancybox.umd.js"></script><script src="https://cdn.cbd.int/instant.page@5.2.0/instantpage.js" type="module"></script><script src="https://cdn.cbd.int/vanilla-lazyload@17.8.5/dist/lazyload.iife.min.js"></script><script src="https://cdn.cbd.int/node-snackbar@0.1.16/dist/snackbar.min.js"></script><script>function panguFn () {
  if (typeof pangu === 'object') pangu.autoSpacingPage()
  else {
    getScript('https://cdn.cbd.int/pangu@4.0.7/dist/browser/pangu.min.js')
      .then(() => {
        pangu.autoSpacingPage()
      })
  }
}

function panguInit () {
  if (false){
    GLOBAL_CONFIG_SITE.isPost && panguFn()
  } else {
    panguFn()
  }
}

document.addEventListener('DOMContentLoaded', panguInit)</script><canvas id="universe"></canvas><script async="" src="https://npm.elemecdn.com/anzhiyu-theme-static@1.0.0/dark/dark.js"></script><script>// 消除控制台打印
var HoldLog = console.log;
console.log = function () {};
let now1 = new Date();
queueMicrotask(() => {
  const Log = function () {
    HoldLog.apply(console, arguments);
  }; //在恢复前输出日志
  const grt = new Date("10/27/2024 00:00:00"); //此处修改你的建站时间或者网站上线时间
  now1.setTime(now1.getTime() + 250);
  const days = (now1 - grt) / 1000 / 60 / 60 / 24;
  const dnum = Math.floor(days);
  const ascll = [
    `欢迎使用安知鱼!`,
    `生活明朗, 万物可爱`,
    `
        
       █████╗ ███╗   ██╗███████╗██╗  ██╗██╗██╗   ██╗██╗   ██╗
      ██╔══██╗████╗  ██║╚══███╔╝██║  ██║██║╚██╗ ██╔╝██║   ██║
      ███████║██╔██╗ ██║  ███╔╝ ███████║██║ ╚████╔╝ ██║   ██║
      ██╔══██║██║╚██╗██║ ███╔╝  ██╔══██║██║  ╚██╔╝  ██║   ██║
      ██║  ██║██║ ╚████║███████╗██║  ██║██║   ██║   ╚██████╔╝
      ╚═╝  ╚═╝╚═╝  ╚═══╝╚══════╝╚═╝  ╚═╝╚═╝   ╚═╝    ╚═════╝
        
        `,
    "已上线",
    dnum,
    "天",
    "©2024 By 安知鱼 V1.6.14",
  ];
  const ascll2 = [`NCC2-036`, `调用前置摄像头拍照成功，识别为【小笨蛋】.`, `Photo captured: `, `🤪`];

  setTimeout(
    Log.bind(
      console,
      `\n%c${ascll[0]} %c ${ascll[1]} %c ${ascll[2]} %c${ascll[3]}%c ${ascll[4]}%c ${ascll[5]}\n\n%c ${ascll[6]}\n`,
      "color:#425AEF",
      "",
      "color:#425AEF",
      "color:#425AEF",
      "",
      "color:#425AEF",
      ""
    )
  );
  setTimeout(
    Log.bind(
      console,
      `%c ${ascll2[0]} %c ${ascll2[1]} %c \n${ascll2[2]} %c\n${ascll2[3]}\n`,
      "color:white; background-color:#4fd953",
      "",
      "",
      'background:url("https://npm.elemecdn.com/anzhiyu-blog@1.1.6/img/post/common/tinggge.gif") no-repeat;font-size:450%'
    )
  );

  setTimeout(Log.bind(console, "%c WELCOME %c 你好，小笨蛋.", "color:white; background-color:#4f90d9", ""));

  setTimeout(
    console.warn.bind(
      console,
      "%c ⚡ Powered by 安知鱼 %c 你正在访问 宋书生 的博客.",
      "color:white; background-color:#f0ad4e",
      ""
    )
  );

  setTimeout(Log.bind(console, "%c W23-12 %c 你已打开控制台.", "color:white; background-color:#4f90d9", ""));

  setTimeout(
    console.warn.bind(console, "%c S013-782 %c 你现在正处于监控中.", "color:white; background-color:#d9534f", "")
  );
});</script><script async="" src="/anzhiyu/random.js"></script><script src="/js/search/local-search.js"></script><div class="js-pjax"><script>if (!window.MathJax) {
  window.MathJax = {
    tex: {
      inlineMath: [['$', '$'], ['\\(', '\\)']],
      tags: 'ams'
    },
    chtml: {
      scale: 1.1
    },
    options: {
      renderActions: {
        findScript: [10, doc => {
          for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
            const display = !!node.type.match(/; *mode=display/)
            const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
            const text = document.createTextNode('')
            node.parentNode.replaceChild(text, node)
            math.start = {node: text, delim: '', n: 0}
            math.end = {node: text, delim: '', n: 0}
            doc.math.push(math)
          }
        }, '']
      }
    }
  }
  
  const script = document.createElement('script')
  script.src = 'https://cdn.cbd.int/mathjax@3.2.2/es5/tex-mml-chtml.js'
  script.id = 'MathJax-script'
  script.async = true
  document.head.appendChild(script)
} else {
  MathJax.startup.document.state(0)
  MathJax.texReset()
  MathJax.typesetPromise()
}</script><link rel="stylesheet" type="text/css" href="https://cdn.cbd.int/katex@0.16.0/dist/katex.min.css"><script src="https://cdn.cbd.int/katex@0.16.0/dist/contrib/copy-tex.min.js"></script><script>(() => {
  document.querySelectorAll('#article-container span.katex-display').forEach(item => {
    anzhiyu.wrap(item, 'div', { class: 'katex-wrap'})
  })
})()</script><script>(() => {
  const init = () => {
    twikoo.init(Object.assign({
      el: '#twikoo-wrap',
      envId: 'https://smallscholar-twikoo.hf.space',
      region: '',
      onCommentLoaded: () => {
        anzhiyu.loadLightbox(document.querySelectorAll('#twikoo .tk-content img:not(.tk-owo-emotion)'))
      }
    }, null))
  }

  const loadTwikoo = () => {
    if (typeof twikoo === 'object') setTimeout(runFn,0)
    else getScript('https://cdn.cbd.int/twikoo@1.6.39/dist/twikoo.all.min.js').then(runFn)
  }

  const getCount = () => {
    const countELement = document.getElementById('twikoo-count')
    if(!countELement) return
    twikoo.getCommentsCount({
      envId: 'https://smallscholar-twikoo.hf.space',
      region: '',
      urls: [window.location.pathname],
      includeReply: false
    }).then(res => {
      countELement.textContent = res[0].count
    }).catch(err => {
      console.error(err)
    })
  }

  const runFn = () => {
    init();
    GLOBAL_CONFIG_SITE.isPost && getCount()
  }

  if ('Twikoo' === 'Twikoo' || !true) {
    if (true) anzhiyu.loadComment(document.getElementById('twikoo-wrap'), loadTwikoo)
    else {
      loadTwikoo()
    }
  } else {
    window.loadOtherComment = loadTwikoo
  }
})()</script><input type="hidden" name="page-type" id="page-type" value="post"><script async="" src="/js/anzhiyu/comment_barrage.js"></script></div><script>window.addEventListener('load', () => {
  const changeContent = (content) => {
    if (content === '') return content

    content = content.replace(/<img.*?src="(.*?)"?[^\>]+>/ig, '[图片]') // replace image link
    content = content.replace(/<a[^>]+?href=["']?([^"']+)["']?[^>]*>([^<]+)<\/a>/gi, '[链接]') // replace url
    content = content.replace(/<pre><code>.*?<\/pre>/gi, '[代码]') // replace code
    content = content.replace(/<[^>]+>/g,"") // remove html tag

    if (content.length > 150) {
      content = content.substring(0,150) + '...'
    }
    return content
  }

  const getComment = () => {
    const runTwikoo = () => {
      twikoo.getRecentComments({
        envId: 'https://smallscholar-twikoo.hf.space',
        region: '',
        pageSize: 6,
        includeReply: true
      }).then(function (res) {
        const twikooArray = res.map(e => {
          return {
            'content': changeContent(e.comment),
            'avatar': e.avatar,
            'nick': e.nick,
            'url': e.url + '#' + e.id,
            'date': new Date(e.created).toISOString()
          }
        })

        saveToLocal.set('twikoo-newest-comments', JSON.stringify(twikooArray), 10/(60*24))
        generateHtml(twikooArray)
      }).catch(function (err) {
        const $dom = document.querySelector('#card-newest-comments .aside-list')
        $dom.textContent= "无法获取评论，请确认相关配置是否正确"
      })
    }

    if (typeof twikoo === 'object') {
      runTwikoo()
    } else {
      getScript('https://cdn.cbd.int/twikoo@1.6.39/dist/twikoo.all.min.js').then(runTwikoo)
    }
  }

  const generateHtml = array => {
    let result = ''

    if (array.length) {
      for (let i = 0; i < array.length; i++) {
        result += '<div class=\'aside-list-item\'>'

        if (true) {
          const name = 'data-lazy-src'
          result += `<a href='${array[i].url}' class='thumbnail'><img ${name}='${array[i].avatar}' alt='${array[i].nick}'><div class='name'><span>${array[i].nick} </span></div></a>`
        }
        
        result += `<div class='content'>
        <a class='comment' href='${array[i].url}' title='${array[i].content}'>${array[i].content}</a>
        <time datetime="${array[i].date}">${anzhiyu.diffDate(array[i].date, true)}</time></div>
        </div>`
      }
    } else {
      result += '没有评论'
    }

    let $dom = document.querySelector('#card-newest-comments .aside-list')
    $dom && ($dom.innerHTML= result)
    window.lazyLoadInstance && window.lazyLoadInstance.update()
    window.pjax && window.pjax.refresh($dom)
  }

  const newestCommentInit = () => {
    if (document.querySelector('#card-newest-comments .aside-list')) {
      const data = saveToLocal.get('twikoo-newest-comments')
      if (data) {
        generateHtml(JSON.parse(data))
      } else {
        getComment()
      }
    }
  }

  newestCommentInit()
  document.addEventListener('pjax:complete', newestCommentInit)
})</script><script async="" data-pjax="" src="https://npm.elemecdn.com/anzhiyu-theme-static@1.0.1/bubble/bubble.js"></script><script>var visitorMail = "";
</script><script async="" data-pjax="" src="https://cdn.cbd.int/anzhiyu-theme-static@1.0.0/waterfall/waterfall.js"></script><script src="https://lf3-cdn-tos.bytecdntp.com/cdn/expire-1-M/qrcodejs/1.0.0/qrcode.min.js"></script><script src="/js/anzhiyu/right_click_menu.js"></script><link rel="stylesheet" href="https://cdn.cbd.int/anzhiyu-theme-static@1.1.9/icon/ali_iconfont_css.css"><script src="https://cdn.cbd.int/butterfly-extsrc@1.1.3/dist/activate-power-mode.min.js"></script><script>POWERMODE.colorful = true;
POWERMODE.shake = false;
POWERMODE.mobile = false;
document.body.addEventListener('input', POWERMODE);
</script><script>(() => {
  const isChatBtn = true
  const isChatHideShow = true

  if (isChatBtn) {
    const close = () => {
      Chatra('minimizeWidget')
      Chatra('hide')
    }

    const open = () => {
      Chatra('openChat', true)
      Chatra('show')
    }

    window.ChatraSetup = {
      startHidden: true
    }
  
    window.chatBtnFn = () => {
      const isShow = document.getElementById('chatra').classList.contains('chatra--expanded')
      isShow ? close() : open()
    }
  } else if (isChatHideShow) {
    window.chatBtn = {
      hide: () => {
        Chatra('hide')
      },
      show: () => {
        Chatra('show')
      }
    }
  }

  (function(d, w, c) {
    w.ChatraID = 'j5CFcoznvMTcHnZhc'
    var s = d.createElement('script')
    w[c] = w[c] || function() {
        (w[c].q = w[c].q || []).push(arguments)
    }
    s.async = true
    s.src = 'https://call.chatra.io/chatra.js'
    if (d.head) d.head.appendChild(s)
  })(document, window, 'Chatra')

})()</script><link rel="stylesheet" href="https://cdn.cbd.int/anzhiyu-theme-static@1.0.0/aplayer/APlayer.min.css" media="print" onload="this.media='all'"><script src="https://cdn.cbd.int/anzhiyu-blog-static@1.0.1/js/APlayer.min.js"></script><script src="https://cdn.cbd.int/hexo-anzhiyu-music@1.0.1/assets/js/Meting2.min.js"></script><script src="https://cdn.cbd.int/pjax@0.2.8/pjax.min.js"></script><script>let pjaxSelectors = ["meta[property=\"og:image\"]","meta[property=\"og:title\"]","meta[property=\"og:url\"]","meta[property=\"og:type\"]","meta[property=\"og:site_name\"]","meta[property=\"og:description\"]","head > title","#config-diff","#body-wrap","#rightside-config-hide","#rightside-config-show",".js-pjax"]
var pjax = new Pjax({
  elements: 'a:not([target="_blank"]):not([href="/music/"]):not([href="/no-pjax/"])',
  selectors: pjaxSelectors,
  cacheBust: false,
  analytics: true,
  scrollRestoration: false
})

document.addEventListener('pjax:send', function () {
  // removeEventListener scroll 
  anzhiyu.removeGlobalFnEvent('pjax')
  anzhiyu.removeGlobalFnEvent('themeChange')

  document.getElementById('rightside').classList.remove('rightside-show')
  
  if (window.aplayers) {
    for (let i = 0; i < window.aplayers.length; i++) {
      if (!window.aplayers[i].options.fixed) {
        window.aplayers[i].destroy()
      }
    }
  }

  typeof typed === 'object' && typed.destroy()

  //reset readmode
  const $bodyClassList = document.body.classList
  $bodyClassList.contains('read-mode') && $bodyClassList.remove('read-mode')
})

document.addEventListener('pjax:complete', function () {
  window.refreshFn()

  document.querySelectorAll('script[data-pjax]').forEach(item => {
    const newScript = document.createElement('script')
    const content = item.text || item.textContent || item.innerHTML || ""
    Array.from(item.attributes).forEach(attr => newScript.setAttribute(attr.name, attr.value))
    newScript.appendChild(document.createTextNode(content))
    item.parentNode.replaceChild(newScript, item)
  })

  GLOBAL_CONFIG.islazyload && window.lazyLoadInstance.update()

  typeof panguInit === 'function' && panguInit()

  // google analytics
  typeof gtag === 'function' && gtag('config', 'G-8TT6FESDJF', {'page_path': window.location.pathname});

  // baidu analytics
  typeof _hmt === 'object' && _hmt.push(['_trackPageview',window.location.pathname]);

  typeof loadMeting === 'function' && document.getElementsByClassName('aplayer').length && loadMeting()

  // prismjs
  typeof Prism === 'object' && Prism.highlightAll()
})

document.addEventListener('pjax:error', e => {
  if (e.request.status === 404) {
    pjax.loadUrl('/404.html')
  }
})</script><script async="" data-pjax="" src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script charset="UTF-8" src="https://cdn.cbd.int/anzhiyu-theme-static@1.1.5/accesskey/accesskey.js"></script></div><div id="popup-window"><div class="popup-window-title">通知</div><div class="popup-window-divider"></div><div class="popup-window-content"><div class="popup-tip">你好呀</div><div class="popup-link"><i class="anzhiyufont anzhiyu-icon-arrow-circle-right"></i></div></div></div>
    <link rel="stylesheet" href="https://ai.tianli0.top/static/public/postChatUser_summary.min.css">
    <script>
        let tianliGPT_key = '874d2499b5d9161b9ee19f8e207dafa06adf4a73';
        let tianliGPT_postSelector = '#postchat_postcontent';
        let tianliGPT_Title = '文章摘要';
        let tianliGPT_postURL = '/^https?://[^/]+/[0-9]{4}/[0-9]{2}/[0-9]{2}/';
        let tianliGPT_blacklist = '';
        let tianliGPT_wordLimit = '1000';
        let tianliGPT_typingAnimate = true;
        let tianliGPT_theme = 'default';
        var postChatConfig = {
          backgroundColor: "#3e86f6",
          bottom: "16px",
          left: "97%",
          fill: "#FFFFFF",
          width: "44px",
          frameWidth: "375px",
          frameHeight: "600px",
          defaultInput: true,
          upLoadWeb: true,
          showInviteLink: true,
          userTitle: "PostChat",
          userDesc: "如果你对网站的内容有任何疑问，可以来问我哦～",
          addButton: true,
          beginningText: "这篇文章介绍了",
          userIcon: "https://ai.tianli0.top/static/img/PostChat.webp",
          userMode: "magic",
          defaultChatQuestions: ["你好","你是谁"],
          defaultSearchQuestions: ["视频压缩","设计"]
        };
    </script>
    <script data-postchat_key="874d2499b5d9161b9ee19f8e207dafa06adf4a73" src="https://ai.tianli0.top/static/public/postChatUser.min.js"></script>
  </body></html>